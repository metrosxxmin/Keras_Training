{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To Display the Learning Process (How to use the history object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/soominlee/.pyenv/versions/3.7.5/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/1000\n",
      "700/700 [==============================] - 0s 226us/step - loss: 2.2576 - accuracy: 0.1643 - val_loss: 2.2272 - val_accuracy: 0.1633\n",
      "Epoch 2/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 2.2072 - accuracy: 0.1657 - val_loss: 2.1908 - val_accuracy: 0.1800\n",
      "Epoch 3/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 2.1730 - accuracy: 0.1729 - val_loss: 2.1631 - val_accuracy: 0.1867\n",
      "Epoch 4/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 2.1441 - accuracy: 0.1786 - val_loss: 2.1372 - val_accuracy: 0.1867\n",
      "Epoch 5/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 2.1177 - accuracy: 0.1900 - val_loss: 2.1141 - val_accuracy: 0.1867\n",
      "Epoch 6/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 2.0940 - accuracy: 0.2029 - val_loss: 2.0931 - val_accuracy: 0.2033\n",
      "Epoch 7/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 2.0721 - accuracy: 0.2071 - val_loss: 2.0727 - val_accuracy: 0.2067\n",
      "Epoch 8/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 2.0520 - accuracy: 0.2129 - val_loss: 2.0564 - val_accuracy: 0.2067\n",
      "Epoch 9/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 2.0342 - accuracy: 0.2157 - val_loss: 2.0410 - val_accuracy: 0.2033\n",
      "Epoch 10/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 2.0190 - accuracy: 0.2143 - val_loss: 2.0269 - val_accuracy: 0.2067\n",
      "Epoch 11/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 2.0041 - accuracy: 0.2186 - val_loss: 2.0125 - val_accuracy: 0.2100\n",
      "Epoch 12/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.9911 - accuracy: 0.2200 - val_loss: 2.0037 - val_accuracy: 0.2100\n",
      "Epoch 13/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.9789 - accuracy: 0.2286 - val_loss: 1.9955 - val_accuracy: 0.2100\n",
      "Epoch 14/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.9685 - accuracy: 0.2329 - val_loss: 1.9833 - val_accuracy: 0.2067\n",
      "Epoch 15/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.9582 - accuracy: 0.2214 - val_loss: 1.9753 - val_accuracy: 0.2100\n",
      "Epoch 16/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.9484 - accuracy: 0.2357 - val_loss: 1.9686 - val_accuracy: 0.2000\n",
      "Epoch 17/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.9393 - accuracy: 0.2343 - val_loss: 1.9612 - val_accuracy: 0.2033\n",
      "Epoch 18/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.9309 - accuracy: 0.2314 - val_loss: 1.9537 - val_accuracy: 0.2100\n",
      "Epoch 19/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.9232 - accuracy: 0.2286 - val_loss: 1.9452 - val_accuracy: 0.2100\n",
      "Epoch 20/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.9156 - accuracy: 0.2386 - val_loss: 1.9392 - val_accuracy: 0.2100\n",
      "Epoch 21/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.9085 - accuracy: 0.2343 - val_loss: 1.9363 - val_accuracy: 0.2100\n",
      "Epoch 22/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.9011 - accuracy: 0.2386 - val_loss: 1.9289 - val_accuracy: 0.2033\n",
      "Epoch 23/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.8954 - accuracy: 0.2357 - val_loss: 1.9234 - val_accuracy: 0.2100\n",
      "Epoch 24/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.8895 - accuracy: 0.2314 - val_loss: 1.9201 - val_accuracy: 0.2067\n",
      "Epoch 25/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.8830 - accuracy: 0.2343 - val_loss: 1.9178 - val_accuracy: 0.2167\n",
      "Epoch 26/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.8769 - accuracy: 0.2300 - val_loss: 1.9105 - val_accuracy: 0.2167\n",
      "Epoch 27/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.8715 - accuracy: 0.2357 - val_loss: 1.9098 - val_accuracy: 0.2167\n",
      "Epoch 28/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.8662 - accuracy: 0.2400 - val_loss: 1.9094 - val_accuracy: 0.2000\n",
      "Epoch 29/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.8615 - accuracy: 0.2400 - val_loss: 1.9041 - val_accuracy: 0.1900\n",
      "Epoch 30/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.8565 - accuracy: 0.2243 - val_loss: 1.8976 - val_accuracy: 0.2167\n",
      "Epoch 31/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8513 - accuracy: 0.2471 - val_loss: 1.8971 - val_accuracy: 0.1933\n",
      "Epoch 32/1000\n",
      "700/700 [==============================] - 0s 90us/step - loss: 1.8463 - accuracy: 0.2371 - val_loss: 1.8925 - val_accuracy: 0.1900\n",
      "Epoch 33/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.8423 - accuracy: 0.2229 - val_loss: 1.8874 - val_accuracy: 0.2067\n",
      "Epoch 34/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.8382 - accuracy: 0.2371 - val_loss: 1.8808 - val_accuracy: 0.1933\n",
      "Epoch 35/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.8335 - accuracy: 0.2471 - val_loss: 1.8836 - val_accuracy: 0.1900\n",
      "Epoch 36/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8299 - accuracy: 0.2343 - val_loss: 1.8756 - val_accuracy: 0.1967\n",
      "Epoch 37/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8257 - accuracy: 0.2486 - val_loss: 1.8745 - val_accuracy: 0.1800\n",
      "Epoch 38/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.8220 - accuracy: 0.2371 - val_loss: 1.8700 - val_accuracy: 0.1933\n",
      "Epoch 39/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.8184 - accuracy: 0.2457 - val_loss: 1.8706 - val_accuracy: 0.1767\n",
      "Epoch 40/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.8144 - accuracy: 0.2314 - val_loss: 1.8677 - val_accuracy: 0.2000\n",
      "Epoch 41/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8105 - accuracy: 0.2400 - val_loss: 1.8668 - val_accuracy: 0.1833\n",
      "Epoch 42/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.8075 - accuracy: 0.2471 - val_loss: 1.8635 - val_accuracy: 0.1800\n",
      "Epoch 43/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.8046 - accuracy: 0.2429 - val_loss: 1.8611 - val_accuracy: 0.1700\n",
      "Epoch 44/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.8001 - accuracy: 0.2371 - val_loss: 1.8566 - val_accuracy: 0.1967\n",
      "Epoch 45/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.7970 - accuracy: 0.2429 - val_loss: 1.8564 - val_accuracy: 0.1700\n",
      "Epoch 46/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7939 - accuracy: 0.2271 - val_loss: 1.8528 - val_accuracy: 0.1933\n",
      "Epoch 47/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7913 - accuracy: 0.2600 - val_loss: 1.8551 - val_accuracy: 0.1833\n",
      "Epoch 48/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7886 - accuracy: 0.2471 - val_loss: 1.8543 - val_accuracy: 0.1867\n",
      "Epoch 49/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.7858 - accuracy: 0.2486 - val_loss: 1.8504 - val_accuracy: 0.1867\n",
      "Epoch 50/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7819 - accuracy: 0.2471 - val_loss: 1.8443 - val_accuracy: 0.2267\n",
      "Epoch 51/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7794 - accuracy: 0.2643 - val_loss: 1.8468 - val_accuracy: 0.1900\n",
      "Epoch 52/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.7762 - accuracy: 0.2486 - val_loss: 1.8411 - val_accuracy: 0.1933\n",
      "Epoch 53/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.7744 - accuracy: 0.2514 - val_loss: 1.8486 - val_accuracy: 0.2000\n",
      "Epoch 54/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7716 - accuracy: 0.2700 - val_loss: 1.8472 - val_accuracy: 0.1800\n",
      "Epoch 55/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.7687 - accuracy: 0.2500 - val_loss: 1.8364 - val_accuracy: 0.2033\n",
      "Epoch 56/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7672 - accuracy: 0.2543 - val_loss: 1.8430 - val_accuracy: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.7641 - accuracy: 0.2714 - val_loss: 1.8390 - val_accuracy: 0.2167\n",
      "Epoch 58/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.7616 - accuracy: 0.2557 - val_loss: 1.8347 - val_accuracy: 0.2267\n",
      "Epoch 59/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.7590 - accuracy: 0.2671 - val_loss: 1.8329 - val_accuracy: 0.2233\n",
      "Epoch 60/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7552 - accuracy: 0.2614 - val_loss: 1.8256 - val_accuracy: 0.2500\n",
      "Epoch 61/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7566 - accuracy: 0.2814 - val_loss: 1.8336 - val_accuracy: 0.2400\n",
      "Epoch 62/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.7531 - accuracy: 0.2729 - val_loss: 1.8312 - val_accuracy: 0.2267\n",
      "Epoch 63/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7505 - accuracy: 0.2857 - val_loss: 1.8299 - val_accuracy: 0.2000\n",
      "Epoch 64/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.7484 - accuracy: 0.2800 - val_loss: 1.8268 - val_accuracy: 0.2200\n",
      "Epoch 65/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7457 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2033\n",
      "Epoch 66/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.7439 - accuracy: 0.2786 - val_loss: 1.8296 - val_accuracy: 0.2067\n",
      "Epoch 67/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.7419 - accuracy: 0.2700 - val_loss: 1.8299 - val_accuracy: 0.2067\n",
      "Epoch 68/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7405 - accuracy: 0.2729 - val_loss: 1.8238 - val_accuracy: 0.2000\n",
      "Epoch 69/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7376 - accuracy: 0.2814 - val_loss: 1.8298 - val_accuracy: 0.2167\n",
      "Epoch 70/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7356 - accuracy: 0.2857 - val_loss: 1.8269 - val_accuracy: 0.2433\n",
      "Epoch 71/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.7345 - accuracy: 0.2800 - val_loss: 1.8214 - val_accuracy: 0.2167\n",
      "Epoch 72/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7328 - accuracy: 0.2857 - val_loss: 1.8226 - val_accuracy: 0.2133\n",
      "Epoch 73/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7298 - accuracy: 0.2800 - val_loss: 1.8252 - val_accuracy: 0.2467\n",
      "Epoch 74/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.7283 - accuracy: 0.2857 - val_loss: 1.8257 - val_accuracy: 0.1967\n",
      "Epoch 75/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.7268 - accuracy: 0.2786 - val_loss: 1.8190 - val_accuracy: 0.2267\n",
      "Epoch 76/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7255 - accuracy: 0.2857 - val_loss: 1.8196 - val_accuracy: 0.2233\n",
      "Epoch 77/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.7228 - accuracy: 0.3057 - val_loss: 1.8232 - val_accuracy: 0.2033\n",
      "Epoch 78/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.7212 - accuracy: 0.2857 - val_loss: 1.8187 - val_accuracy: 0.1933\n",
      "Epoch 79/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.7199 - accuracy: 0.2829 - val_loss: 1.8203 - val_accuracy: 0.2433\n",
      "Epoch 80/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7188 - accuracy: 0.2929 - val_loss: 1.8197 - val_accuracy: 0.2067\n",
      "Epoch 81/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7165 - accuracy: 0.2843 - val_loss: 1.8256 - val_accuracy: 0.2067\n",
      "Epoch 82/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7142 - accuracy: 0.2829 - val_loss: 1.8144 - val_accuracy: 0.2667\n",
      "Epoch 83/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7132 - accuracy: 0.2857 - val_loss: 1.8190 - val_accuracy: 0.2400\n",
      "Epoch 84/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7127 - accuracy: 0.2986 - val_loss: 1.8220 - val_accuracy: 0.2167\n",
      "Epoch 85/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.7097 - accuracy: 0.2971 - val_loss: 1.8159 - val_accuracy: 0.2267\n",
      "Epoch 86/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7082 - accuracy: 0.2800 - val_loss: 1.8136 - val_accuracy: 0.2633\n",
      "Epoch 87/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7051 - accuracy: 0.3100 - val_loss: 1.8191 - val_accuracy: 0.2733\n",
      "Epoch 88/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.7062 - accuracy: 0.3043 - val_loss: 1.8125 - val_accuracy: 0.2433\n",
      "Epoch 89/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.7043 - accuracy: 0.3043 - val_loss: 1.8167 - val_accuracy: 0.2167\n",
      "Epoch 90/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.7027 - accuracy: 0.2843 - val_loss: 1.8151 - val_accuracy: 0.2233\n",
      "Epoch 91/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.7017 - accuracy: 0.3086 - val_loss: 1.8185 - val_accuracy: 0.2167\n",
      "Epoch 92/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6987 - accuracy: 0.3129 - val_loss: 1.8215 - val_accuracy: 0.2067\n",
      "Epoch 93/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6980 - accuracy: 0.3071 - val_loss: 1.8173 - val_accuracy: 0.2767\n",
      "Epoch 94/1000\n",
      "700/700 [==============================] - 0s 85us/step - loss: 1.6970 - accuracy: 0.3157 - val_loss: 1.8176 - val_accuracy: 0.2100\n",
      "Epoch 95/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6943 - accuracy: 0.2986 - val_loss: 1.8194 - val_accuracy: 0.2833\n",
      "Epoch 96/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6948 - accuracy: 0.3014 - val_loss: 1.8095 - val_accuracy: 0.2233\n",
      "Epoch 97/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6930 - accuracy: 0.3057 - val_loss: 1.8228 - val_accuracy: 0.2300\n",
      "Epoch 98/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6921 - accuracy: 0.3043 - val_loss: 1.8117 - val_accuracy: 0.2200\n",
      "Epoch 99/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6901 - accuracy: 0.3129 - val_loss: 1.8252 - val_accuracy: 0.2233\n",
      "Epoch 100/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6890 - accuracy: 0.3129 - val_loss: 1.8210 - val_accuracy: 0.2267\n",
      "Epoch 101/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6878 - accuracy: 0.3143 - val_loss: 1.8190 - val_accuracy: 0.2200\n",
      "Epoch 102/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.6877 - accuracy: 0.3014 - val_loss: 1.8219 - val_accuracy: 0.2300\n",
      "Epoch 103/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6843 - accuracy: 0.3000 - val_loss: 1.8102 - val_accuracy: 0.2500\n",
      "Epoch 104/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6842 - accuracy: 0.3200 - val_loss: 1.8122 - val_accuracy: 0.2200\n",
      "Epoch 105/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6821 - accuracy: 0.3071 - val_loss: 1.8063 - val_accuracy: 0.2067\n",
      "Epoch 106/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6814 - accuracy: 0.3114 - val_loss: 1.8173 - val_accuracy: 0.2200\n",
      "Epoch 107/1000\n",
      "700/700 [==============================] - 0s 88us/step - loss: 1.6805 - accuracy: 0.3071 - val_loss: 1.8228 - val_accuracy: 0.2367\n",
      "Epoch 108/1000\n",
      "700/700 [==============================] - 0s 93us/step - loss: 1.6784 - accuracy: 0.3071 - val_loss: 1.8167 - val_accuracy: 0.2767\n",
      "Epoch 109/1000\n",
      "700/700 [==============================] - 0s 109us/step - loss: 1.6782 - accuracy: 0.3143 - val_loss: 1.8178 - val_accuracy: 0.2300\n",
      "Epoch 110/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6775 - accuracy: 0.3171 - val_loss: 1.8147 - val_accuracy: 0.2133\n",
      "Epoch 111/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6775 - accuracy: 0.3043 - val_loss: 1.8173 - val_accuracy: 0.2233\n",
      "Epoch 112/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6745 - accuracy: 0.3129 - val_loss: 1.8193 - val_accuracy: 0.2267\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 73us/step - loss: 1.6737 - accuracy: 0.3100 - val_loss: 1.8196 - val_accuracy: 0.2300\n",
      "Epoch 114/1000\n",
      "700/700 [==============================] - 0s 98us/step - loss: 1.6724 - accuracy: 0.3014 - val_loss: 1.8221 - val_accuracy: 0.2300\n",
      "Epoch 115/1000\n",
      "700/700 [==============================] - 0s 95us/step - loss: 1.6711 - accuracy: 0.3071 - val_loss: 1.8128 - val_accuracy: 0.2333\n",
      "Epoch 116/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6703 - accuracy: 0.3157 - val_loss: 1.8255 - val_accuracy: 0.2300\n",
      "Epoch 117/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.6694 - accuracy: 0.3100 - val_loss: 1.8228 - val_accuracy: 0.2333\n",
      "Epoch 118/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6682 - accuracy: 0.3114 - val_loss: 1.8262 - val_accuracy: 0.2333\n",
      "Epoch 119/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6670 - accuracy: 0.3257 - val_loss: 1.8216 - val_accuracy: 0.2200\n",
      "Epoch 120/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6661 - accuracy: 0.3129 - val_loss: 1.8219 - val_accuracy: 0.2200\n",
      "Epoch 121/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6646 - accuracy: 0.3071 - val_loss: 1.8132 - val_accuracy: 0.2233\n",
      "Epoch 122/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6637 - accuracy: 0.3229 - val_loss: 1.8194 - val_accuracy: 0.2200\n",
      "Epoch 123/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.6629 - accuracy: 0.3100 - val_loss: 1.8139 - val_accuracy: 0.2200\n",
      "Epoch 124/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6619 - accuracy: 0.3143 - val_loss: 1.8187 - val_accuracy: 0.2267\n",
      "Epoch 125/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.6606 - accuracy: 0.3257 - val_loss: 1.8212 - val_accuracy: 0.2333\n",
      "Epoch 126/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6592 - accuracy: 0.3143 - val_loss: 1.8245 - val_accuracy: 0.2233\n",
      "Epoch 127/1000\n",
      "700/700 [==============================] - 0s 96us/step - loss: 1.6583 - accuracy: 0.3129 - val_loss: 1.8147 - val_accuracy: 0.2333\n",
      "Epoch 128/1000\n",
      "700/700 [==============================] - 0s 104us/step - loss: 1.6565 - accuracy: 0.3300 - val_loss: 1.8280 - val_accuracy: 0.2300\n",
      "Epoch 129/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6570 - accuracy: 0.3143 - val_loss: 1.8193 - val_accuracy: 0.2200\n",
      "Epoch 130/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.6548 - accuracy: 0.3214 - val_loss: 1.8124 - val_accuracy: 0.2533\n",
      "Epoch 131/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6547 - accuracy: 0.3229 - val_loss: 1.8202 - val_accuracy: 0.2500\n",
      "Epoch 132/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6545 - accuracy: 0.3200 - val_loss: 1.8133 - val_accuracy: 0.2267\n",
      "Epoch 133/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.6524 - accuracy: 0.3143 - val_loss: 1.8317 - val_accuracy: 0.2400\n",
      "Epoch 134/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6514 - accuracy: 0.3214 - val_loss: 1.8226 - val_accuracy: 0.2733\n",
      "Epoch 135/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6512 - accuracy: 0.3314 - val_loss: 1.8233 - val_accuracy: 0.2267\n",
      "Epoch 136/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6493 - accuracy: 0.3186 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 137/1000\n",
      "700/700 [==============================] - 0s 86us/step - loss: 1.6483 - accuracy: 0.3214 - val_loss: 1.8191 - val_accuracy: 0.2200\n",
      "Epoch 138/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.6488 - accuracy: 0.3257 - val_loss: 1.8199 - val_accuracy: 0.2167\n",
      "Epoch 139/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6466 - accuracy: 0.3257 - val_loss: 1.8512 - val_accuracy: 0.2433\n",
      "Epoch 140/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6465 - accuracy: 0.3214 - val_loss: 1.8168 - val_accuracy: 0.2200\n",
      "Epoch 141/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6446 - accuracy: 0.3229 - val_loss: 1.8284 - val_accuracy: 0.2267\n",
      "Epoch 142/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6437 - accuracy: 0.3243 - val_loss: 1.8154 - val_accuracy: 0.2633\n",
      "Epoch 143/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6437 - accuracy: 0.3329 - val_loss: 1.8292 - val_accuracy: 0.2433\n",
      "Epoch 144/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6431 - accuracy: 0.3329 - val_loss: 1.8273 - val_accuracy: 0.2300\n",
      "Epoch 145/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6419 - accuracy: 0.3271 - val_loss: 1.8197 - val_accuracy: 0.2200\n",
      "Epoch 146/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6392 - accuracy: 0.3343 - val_loss: 1.8324 - val_accuracy: 0.2233\n",
      "Epoch 147/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6412 - accuracy: 0.3100 - val_loss: 1.8328 - val_accuracy: 0.2333\n",
      "Epoch 148/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6390 - accuracy: 0.3243 - val_loss: 1.8306 - val_accuracy: 0.2500\n",
      "Epoch 149/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6375 - accuracy: 0.3271 - val_loss: 1.8189 - val_accuracy: 0.2133\n",
      "Epoch 150/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6367 - accuracy: 0.3229 - val_loss: 1.8276 - val_accuracy: 0.2233\n",
      "Epoch 151/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6364 - accuracy: 0.3257 - val_loss: 1.8245 - val_accuracy: 0.2267\n",
      "Epoch 152/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6350 - accuracy: 0.3214 - val_loss: 1.8290 - val_accuracy: 0.2233\n",
      "Epoch 153/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6340 - accuracy: 0.3400 - val_loss: 1.8270 - val_accuracy: 0.2300\n",
      "Epoch 154/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6319 - accuracy: 0.3457 - val_loss: 1.8343 - val_accuracy: 0.2233\n",
      "Epoch 155/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6316 - accuracy: 0.3243 - val_loss: 1.8183 - val_accuracy: 0.2367\n",
      "Epoch 156/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6326 - accuracy: 0.3329 - val_loss: 1.8309 - val_accuracy: 0.2200\n",
      "Epoch 157/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6308 - accuracy: 0.3300 - val_loss: 1.8241 - val_accuracy: 0.2200\n",
      "Epoch 158/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6308 - accuracy: 0.3343 - val_loss: 1.8329 - val_accuracy: 0.2300\n",
      "Epoch 159/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6285 - accuracy: 0.3257 - val_loss: 1.8336 - val_accuracy: 0.2433\n",
      "Epoch 160/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.6278 - accuracy: 0.3300 - val_loss: 1.8304 - val_accuracy: 0.2233\n",
      "Epoch 161/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6271 - accuracy: 0.3257 - val_loss: 1.8406 - val_accuracy: 0.2300\n",
      "Epoch 162/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6265 - accuracy: 0.3271 - val_loss: 1.8350 - val_accuracy: 0.2267\n",
      "Epoch 163/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6254 - accuracy: 0.3371 - val_loss: 1.8365 - val_accuracy: 0.2300\n",
      "Epoch 164/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6239 - accuracy: 0.3314 - val_loss: 1.8264 - val_accuracy: 0.2100\n",
      "Epoch 165/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6236 - accuracy: 0.3200 - val_loss: 1.8396 - val_accuracy: 0.2367\n",
      "Epoch 166/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6230 - accuracy: 0.3286 - val_loss: 1.8344 - val_accuracy: 0.2233\n",
      "Epoch 167/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6221 - accuracy: 0.3314 - val_loss: 1.8389 - val_accuracy: 0.2633\n",
      "Epoch 168/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6208 - accuracy: 0.3386 - val_loss: 1.8444 - val_accuracy: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6198 - accuracy: 0.3386 - val_loss: 1.8525 - val_accuracy: 0.2233\n",
      "Epoch 170/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.6191 - accuracy: 0.3371 - val_loss: 1.8369 - val_accuracy: 0.2233\n",
      "Epoch 171/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6170 - accuracy: 0.3271 - val_loss: 1.8517 - val_accuracy: 0.2600\n",
      "Epoch 172/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6164 - accuracy: 0.3386 - val_loss: 1.8397 - val_accuracy: 0.2133\n",
      "Epoch 173/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6182 - accuracy: 0.3386 - val_loss: 1.8392 - val_accuracy: 0.2367\n",
      "Epoch 174/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6167 - accuracy: 0.3300 - val_loss: 1.8420 - val_accuracy: 0.2200\n",
      "Epoch 175/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6166 - accuracy: 0.3357 - val_loss: 1.8406 - val_accuracy: 0.2200\n",
      "Epoch 176/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6143 - accuracy: 0.3229 - val_loss: 1.8437 - val_accuracy: 0.2600\n",
      "Epoch 177/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6134 - accuracy: 0.3371 - val_loss: 1.8384 - val_accuracy: 0.2167\n",
      "Epoch 178/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6139 - accuracy: 0.3371 - val_loss: 1.8446 - val_accuracy: 0.2267\n",
      "Epoch 179/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6134 - accuracy: 0.3400 - val_loss: 1.8376 - val_accuracy: 0.2233\n",
      "Epoch 180/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6110 - accuracy: 0.3371 - val_loss: 1.8415 - val_accuracy: 0.2667\n",
      "Epoch 181/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6115 - accuracy: 0.3457 - val_loss: 1.8339 - val_accuracy: 0.2567\n",
      "Epoch 182/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6106 - accuracy: 0.3471 - val_loss: 1.8365 - val_accuracy: 0.2167\n",
      "Epoch 183/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6115 - accuracy: 0.3300 - val_loss: 1.8411 - val_accuracy: 0.2333\n",
      "Epoch 184/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6093 - accuracy: 0.3443 - val_loss: 1.8453 - val_accuracy: 0.2267\n",
      "Epoch 185/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6076 - accuracy: 0.3386 - val_loss: 1.8641 - val_accuracy: 0.2200\n",
      "Epoch 186/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6086 - accuracy: 0.3443 - val_loss: 1.8449 - val_accuracy: 0.2233\n",
      "Epoch 187/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6065 - accuracy: 0.3543 - val_loss: 1.8442 - val_accuracy: 0.2167\n",
      "Epoch 188/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6075 - accuracy: 0.3386 - val_loss: 1.8412 - val_accuracy: 0.2133\n",
      "Epoch 189/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6045 - accuracy: 0.3529 - val_loss: 1.8517 - val_accuracy: 0.2233\n",
      "Epoch 190/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6065 - accuracy: 0.3314 - val_loss: 1.8401 - val_accuracy: 0.2300\n",
      "Epoch 191/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6042 - accuracy: 0.3529 - val_loss: 1.8564 - val_accuracy: 0.2233\n",
      "Epoch 192/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.6044 - accuracy: 0.3500 - val_loss: 1.8503 - val_accuracy: 0.2200\n",
      "Epoch 193/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6029 - accuracy: 0.3357 - val_loss: 1.8539 - val_accuracy: 0.2267\n",
      "Epoch 194/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.6025 - accuracy: 0.3414 - val_loss: 1.8470 - val_accuracy: 0.2267\n",
      "Epoch 195/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.6019 - accuracy: 0.3457 - val_loss: 1.8453 - val_accuracy: 0.2467\n",
      "Epoch 196/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.6016 - accuracy: 0.3514 - val_loss: 1.8472 - val_accuracy: 0.2167\n",
      "Epoch 197/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.6002 - accuracy: 0.3443 - val_loss: 1.8488 - val_accuracy: 0.2300\n",
      "Epoch 198/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.6005 - accuracy: 0.3386 - val_loss: 1.8591 - val_accuracy: 0.2200\n",
      "Epoch 199/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.6003 - accuracy: 0.3429 - val_loss: 1.8558 - val_accuracy: 0.2200\n",
      "Epoch 200/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5975 - accuracy: 0.3457 - val_loss: 1.8604 - val_accuracy: 0.2633\n",
      "Epoch 201/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5986 - accuracy: 0.3457 - val_loss: 1.8469 - val_accuracy: 0.2167\n",
      "Epoch 202/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5979 - accuracy: 0.3414 - val_loss: 1.8478 - val_accuracy: 0.2100\n",
      "Epoch 203/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5965 - accuracy: 0.3343 - val_loss: 1.8562 - val_accuracy: 0.2267\n",
      "Epoch 204/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5953 - accuracy: 0.3557 - val_loss: 1.8461 - val_accuracy: 0.2067\n",
      "Epoch 205/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.5953 - accuracy: 0.3429 - val_loss: 1.8508 - val_accuracy: 0.2200\n",
      "Epoch 206/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5946 - accuracy: 0.3500 - val_loss: 1.8463 - val_accuracy: 0.2133\n",
      "Epoch 207/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5947 - accuracy: 0.3543 - val_loss: 1.8537 - val_accuracy: 0.2233\n",
      "Epoch 208/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5920 - accuracy: 0.3414 - val_loss: 1.8557 - val_accuracy: 0.2233\n",
      "Epoch 209/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5919 - accuracy: 0.3514 - val_loss: 1.8521 - val_accuracy: 0.2300\n",
      "Epoch 210/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5915 - accuracy: 0.3443 - val_loss: 1.8523 - val_accuracy: 0.2267\n",
      "Epoch 211/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5903 - accuracy: 0.3371 - val_loss: 1.8456 - val_accuracy: 0.2567\n",
      "Epoch 212/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5913 - accuracy: 0.3471 - val_loss: 1.8593 - val_accuracy: 0.2200\n",
      "Epoch 213/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5894 - accuracy: 0.3500 - val_loss: 1.8519 - val_accuracy: 0.2233\n",
      "Epoch 214/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5905 - accuracy: 0.3457 - val_loss: 1.8541 - val_accuracy: 0.2267\n",
      "Epoch 215/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5886 - accuracy: 0.3514 - val_loss: 1.8602 - val_accuracy: 0.2667\n",
      "Epoch 216/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5895 - accuracy: 0.3486 - val_loss: 1.8624 - val_accuracy: 0.2267\n",
      "Epoch 217/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5881 - accuracy: 0.3471 - val_loss: 1.8638 - val_accuracy: 0.2300\n",
      "Epoch 218/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5876 - accuracy: 0.3486 - val_loss: 1.8600 - val_accuracy: 0.2300\n",
      "Epoch 219/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5865 - accuracy: 0.3500 - val_loss: 1.8659 - val_accuracy: 0.2267\n",
      "Epoch 220/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5855 - accuracy: 0.3514 - val_loss: 1.8581 - val_accuracy: 0.2267\n",
      "Epoch 221/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5855 - accuracy: 0.3471 - val_loss: 1.8621 - val_accuracy: 0.2267\n",
      "Epoch 222/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5845 - accuracy: 0.3514 - val_loss: 1.8751 - val_accuracy: 0.2500\n",
      "Epoch 223/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5844 - accuracy: 0.3443 - val_loss: 1.8615 - val_accuracy: 0.2600\n",
      "Epoch 224/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5845 - accuracy: 0.3529 - val_loss: 1.8766 - val_accuracy: 0.2467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5833 - accuracy: 0.3457 - val_loss: 1.8572 - val_accuracy: 0.2167\n",
      "Epoch 226/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5835 - accuracy: 0.3486 - val_loss: 1.8686 - val_accuracy: 0.2233\n",
      "Epoch 227/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5825 - accuracy: 0.3486 - val_loss: 1.8611 - val_accuracy: 0.2133\n",
      "Epoch 228/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5825 - accuracy: 0.3443 - val_loss: 1.8693 - val_accuracy: 0.2267\n",
      "Epoch 229/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5801 - accuracy: 0.3471 - val_loss: 1.8688 - val_accuracy: 0.2233\n",
      "Epoch 230/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5818 - accuracy: 0.3471 - val_loss: 1.8635 - val_accuracy: 0.2133\n",
      "Epoch 231/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5797 - accuracy: 0.3529 - val_loss: 1.8605 - val_accuracy: 0.2200\n",
      "Epoch 232/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5809 - accuracy: 0.3514 - val_loss: 1.8730 - val_accuracy: 0.2133\n",
      "Epoch 233/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.5796 - accuracy: 0.3486 - val_loss: 1.8781 - val_accuracy: 0.2200\n",
      "Epoch 234/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5791 - accuracy: 0.3457 - val_loss: 1.8666 - val_accuracy: 0.2133\n",
      "Epoch 235/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5777 - accuracy: 0.3571 - val_loss: 1.8693 - val_accuracy: 0.2100\n",
      "Epoch 236/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5778 - accuracy: 0.3443 - val_loss: 1.8664 - val_accuracy: 0.2133\n",
      "Epoch 237/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5770 - accuracy: 0.3429 - val_loss: 1.8718 - val_accuracy: 0.2300\n",
      "Epoch 238/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5774 - accuracy: 0.3471 - val_loss: 1.8613 - val_accuracy: 0.2200\n",
      "Epoch 239/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5770 - accuracy: 0.3571 - val_loss: 1.8682 - val_accuracy: 0.2267\n",
      "Epoch 240/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8719 - val_accuracy: 0.2500\n",
      "Epoch 241/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5749 - accuracy: 0.3571 - val_loss: 1.8738 - val_accuracy: 0.2433\n",
      "Epoch 242/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5743 - accuracy: 0.3514 - val_loss: 1.8733 - val_accuracy: 0.2100\n",
      "Epoch 243/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5743 - accuracy: 0.3629 - val_loss: 1.8806 - val_accuracy: 0.2200\n",
      "Epoch 244/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5713 - accuracy: 0.3557 - val_loss: 1.8724 - val_accuracy: 0.2200\n",
      "Epoch 245/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5715 - accuracy: 0.3586 - val_loss: 1.8838 - val_accuracy: 0.2233\n",
      "Epoch 246/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5712 - accuracy: 0.3543 - val_loss: 1.8710 - val_accuracy: 0.2533\n",
      "Epoch 247/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5722 - accuracy: 0.3557 - val_loss: 1.8631 - val_accuracy: 0.2167\n",
      "Epoch 248/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5716 - accuracy: 0.3557 - val_loss: 1.8700 - val_accuracy: 0.2233\n",
      "Epoch 249/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5712 - accuracy: 0.3471 - val_loss: 1.8840 - val_accuracy: 0.2233\n",
      "Epoch 250/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5680 - accuracy: 0.3657 - val_loss: 1.8981 - val_accuracy: 0.2167\n",
      "Epoch 251/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5704 - accuracy: 0.3486 - val_loss: 1.8793 - val_accuracy: 0.2400\n",
      "Epoch 252/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5682 - accuracy: 0.3643 - val_loss: 1.8744 - val_accuracy: 0.2200\n",
      "Epoch 253/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5689 - accuracy: 0.3586 - val_loss: 1.8820 - val_accuracy: 0.2133\n",
      "Epoch 254/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5677 - accuracy: 0.3571 - val_loss: 1.8835 - val_accuracy: 0.2267\n",
      "Epoch 255/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5681 - accuracy: 0.3457 - val_loss: 1.8713 - val_accuracy: 0.2267\n",
      "Epoch 256/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5657 - accuracy: 0.3571 - val_loss: 1.8761 - val_accuracy: 0.2533\n",
      "Epoch 257/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5667 - accuracy: 0.3514 - val_loss: 1.8912 - val_accuracy: 0.2467\n",
      "Epoch 258/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5649 - accuracy: 0.3614 - val_loss: 1.8946 - val_accuracy: 0.2567\n",
      "Epoch 259/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5648 - accuracy: 0.3643 - val_loss: 1.8911 - val_accuracy: 0.2167\n",
      "Epoch 260/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5657 - accuracy: 0.3600 - val_loss: 1.8989 - val_accuracy: 0.2200\n",
      "Epoch 261/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5637 - accuracy: 0.3571 - val_loss: 1.8751 - val_accuracy: 0.2167\n",
      "Epoch 262/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5638 - accuracy: 0.3614 - val_loss: 1.8836 - val_accuracy: 0.2100\n",
      "Epoch 263/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5631 - accuracy: 0.3629 - val_loss: 1.8858 - val_accuracy: 0.2100\n",
      "Epoch 264/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5640 - accuracy: 0.3571 - val_loss: 1.8812 - val_accuracy: 0.2133\n",
      "Epoch 265/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5638 - accuracy: 0.3686 - val_loss: 1.8902 - val_accuracy: 0.2200\n",
      "Epoch 266/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5614 - accuracy: 0.3614 - val_loss: 1.8968 - val_accuracy: 0.2500\n",
      "Epoch 267/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5612 - accuracy: 0.3629 - val_loss: 1.8918 - val_accuracy: 0.2300\n",
      "Epoch 268/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5613 - accuracy: 0.3614 - val_loss: 1.8757 - val_accuracy: 0.2100\n",
      "Epoch 269/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5601 - accuracy: 0.3643 - val_loss: 1.8854 - val_accuracy: 0.2133\n",
      "Epoch 270/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5594 - accuracy: 0.3671 - val_loss: 1.8674 - val_accuracy: 0.2333\n",
      "Epoch 271/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5610 - accuracy: 0.3657 - val_loss: 1.8914 - val_accuracy: 0.2333\n",
      "Epoch 272/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5595 - accuracy: 0.3600 - val_loss: 1.9030 - val_accuracy: 0.2267\n",
      "Epoch 273/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5591 - accuracy: 0.3571 - val_loss: 1.8964 - val_accuracy: 0.2200\n",
      "Epoch 274/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5589 - accuracy: 0.3457 - val_loss: 1.8841 - val_accuracy: 0.2233\n",
      "Epoch 275/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5589 - accuracy: 0.3629 - val_loss: 1.8914 - val_accuracy: 0.2200\n",
      "Epoch 276/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5579 - accuracy: 0.3529 - val_loss: 1.8967 - val_accuracy: 0.2533\n",
      "Epoch 277/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5581 - accuracy: 0.3714 - val_loss: 1.8909 - val_accuracy: 0.2167\n",
      "Epoch 278/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5578 - accuracy: 0.3600 - val_loss: 1.9032 - val_accuracy: 0.2300\n",
      "Epoch 279/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5559 - accuracy: 0.3571 - val_loss: 1.8859 - val_accuracy: 0.2167\n",
      "Epoch 280/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5559 - accuracy: 0.3700 - val_loss: 1.8876 - val_accuracy: 0.2167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5541 - accuracy: 0.3586 - val_loss: 1.8906 - val_accuracy: 0.2333\n",
      "Epoch 282/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5553 - accuracy: 0.3671 - val_loss: 1.8840 - val_accuracy: 0.2133\n",
      "Epoch 283/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5543 - accuracy: 0.3557 - val_loss: 1.8927 - val_accuracy: 0.2167\n",
      "Epoch 284/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5542 - accuracy: 0.3614 - val_loss: 1.8936 - val_accuracy: 0.2567\n",
      "Epoch 285/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5535 - accuracy: 0.3557 - val_loss: 1.8887 - val_accuracy: 0.2200\n",
      "Epoch 286/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5536 - accuracy: 0.3586 - val_loss: 1.8989 - val_accuracy: 0.2233\n",
      "Epoch 287/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5527 - accuracy: 0.3686 - val_loss: 1.9019 - val_accuracy: 0.2133\n",
      "Epoch 288/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5525 - accuracy: 0.3600 - val_loss: 1.8930 - val_accuracy: 0.2133\n",
      "Epoch 289/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5519 - accuracy: 0.3600 - val_loss: 1.9014 - val_accuracy: 0.2167\n",
      "Epoch 290/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5514 - accuracy: 0.3657 - val_loss: 1.9032 - val_accuracy: 0.2200\n",
      "Epoch 291/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5513 - accuracy: 0.3586 - val_loss: 1.9037 - val_accuracy: 0.2167\n",
      "Epoch 292/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5509 - accuracy: 0.3543 - val_loss: 1.8995 - val_accuracy: 0.2433\n",
      "Epoch 293/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5507 - accuracy: 0.3543 - val_loss: 1.9011 - val_accuracy: 0.2300\n",
      "Epoch 294/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5497 - accuracy: 0.3543 - val_loss: 1.9002 - val_accuracy: 0.2567\n",
      "Epoch 295/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5499 - accuracy: 0.3657 - val_loss: 1.9120 - val_accuracy: 0.2200\n",
      "Epoch 296/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5495 - accuracy: 0.3571 - val_loss: 1.9104 - val_accuracy: 0.2133\n",
      "Epoch 297/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5479 - accuracy: 0.3571 - val_loss: 1.9128 - val_accuracy: 0.2167\n",
      "Epoch 298/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5477 - accuracy: 0.3486 - val_loss: 1.8958 - val_accuracy: 0.2267\n",
      "Epoch 299/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5485 - accuracy: 0.3686 - val_loss: 1.9145 - val_accuracy: 0.2267\n",
      "Epoch 300/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5472 - accuracy: 0.3629 - val_loss: 1.9031 - val_accuracy: 0.2300\n",
      "Epoch 301/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5469 - accuracy: 0.3629 - val_loss: 1.8934 - val_accuracy: 0.2200\n",
      "Epoch 302/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5479 - accuracy: 0.3657 - val_loss: 1.9081 - val_accuracy: 0.2167\n",
      "Epoch 303/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5464 - accuracy: 0.3529 - val_loss: 1.9016 - val_accuracy: 0.2333\n",
      "Epoch 304/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5452 - accuracy: 0.3671 - val_loss: 1.9066 - val_accuracy: 0.2200\n",
      "Epoch 305/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5432 - accuracy: 0.3643 - val_loss: 1.9140 - val_accuracy: 0.2267\n",
      "Epoch 306/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5458 - accuracy: 0.3600 - val_loss: 1.9100 - val_accuracy: 0.2233\n",
      "Epoch 307/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5436 - accuracy: 0.3671 - val_loss: 1.9064 - val_accuracy: 0.2267\n",
      "Epoch 308/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5453 - accuracy: 0.3600 - val_loss: 1.9129 - val_accuracy: 0.2333\n",
      "Epoch 309/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5435 - accuracy: 0.3643 - val_loss: 1.9120 - val_accuracy: 0.2367\n",
      "Epoch 310/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5448 - accuracy: 0.3671 - val_loss: 1.9110 - val_accuracy: 0.2167\n",
      "Epoch 311/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5426 - accuracy: 0.3586 - val_loss: 1.9058 - val_accuracy: 0.2300\n",
      "Epoch 312/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5423 - accuracy: 0.3729 - val_loss: 1.9273 - val_accuracy: 0.2367\n",
      "Epoch 313/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5387 - accuracy: 0.3657 - val_loss: 1.9056 - val_accuracy: 0.2633\n",
      "Epoch 314/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5433 - accuracy: 0.3686 - val_loss: 1.9131 - val_accuracy: 0.2300\n",
      "Epoch 315/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5406 - accuracy: 0.3657 - val_loss: 1.9118 - val_accuracy: 0.2233\n",
      "Epoch 316/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5404 - accuracy: 0.3614 - val_loss: 1.9141 - val_accuracy: 0.2233\n",
      "Epoch 317/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5412 - accuracy: 0.3614 - val_loss: 1.9213 - val_accuracy: 0.2333\n",
      "Epoch 318/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5408 - accuracy: 0.3614 - val_loss: 1.9096 - val_accuracy: 0.2300\n",
      "Epoch 319/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5390 - accuracy: 0.3614 - val_loss: 1.9092 - val_accuracy: 0.2300\n",
      "Epoch 320/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5392 - accuracy: 0.3629 - val_loss: 1.9278 - val_accuracy: 0.2233\n",
      "Epoch 321/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5392 - accuracy: 0.3686 - val_loss: 1.9258 - val_accuracy: 0.2300\n",
      "Epoch 322/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5375 - accuracy: 0.3671 - val_loss: 1.9181 - val_accuracy: 0.2533\n",
      "Epoch 323/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5383 - accuracy: 0.3714 - val_loss: 1.9197 - val_accuracy: 0.2300\n",
      "Epoch 324/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5373 - accuracy: 0.3657 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 325/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5387 - accuracy: 0.3600 - val_loss: 1.9178 - val_accuracy: 0.2133\n",
      "Epoch 326/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5365 - accuracy: 0.3614 - val_loss: 1.9227 - val_accuracy: 0.2200\n",
      "Epoch 327/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5359 - accuracy: 0.3743 - val_loss: 1.9378 - val_accuracy: 0.2333\n",
      "Epoch 328/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5366 - accuracy: 0.3657 - val_loss: 1.9307 - val_accuracy: 0.2233\n",
      "Epoch 329/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5354 - accuracy: 0.3714 - val_loss: 1.9147 - val_accuracy: 0.2300\n",
      "Epoch 330/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5351 - accuracy: 0.3600 - val_loss: 1.9222 - val_accuracy: 0.2333\n",
      "Epoch 331/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5338 - accuracy: 0.3714 - val_loss: 1.9155 - val_accuracy: 0.2200\n",
      "Epoch 332/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5346 - accuracy: 0.3571 - val_loss: 1.9340 - val_accuracy: 0.2500\n",
      "Epoch 333/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.5358 - accuracy: 0.3671 - val_loss: 1.9234 - val_accuracy: 0.2233\n",
      "Epoch 334/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5349 - accuracy: 0.3629 - val_loss: 1.9289 - val_accuracy: 0.2233\n",
      "Epoch 335/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5327 - accuracy: 0.3757 - val_loss: 1.9246 - val_accuracy: 0.2567\n",
      "Epoch 336/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5335 - accuracy: 0.3786 - val_loss: 1.9184 - val_accuracy: 0.2300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5330 - accuracy: 0.3757 - val_loss: 1.9324 - val_accuracy: 0.2300\n",
      "Epoch 338/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5320 - accuracy: 0.3743 - val_loss: 1.9238 - val_accuracy: 0.2133\n",
      "Epoch 339/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5314 - accuracy: 0.3700 - val_loss: 1.9157 - val_accuracy: 0.2167\n",
      "Epoch 340/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5328 - accuracy: 0.3729 - val_loss: 1.9403 - val_accuracy: 0.2267\n",
      "Epoch 341/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5317 - accuracy: 0.3757 - val_loss: 1.9258 - val_accuracy: 0.2267\n",
      "Epoch 342/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5313 - accuracy: 0.3600 - val_loss: 1.9441 - val_accuracy: 0.2167\n",
      "Epoch 343/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5310 - accuracy: 0.3686 - val_loss: 1.9333 - val_accuracy: 0.2267\n",
      "Epoch 344/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5308 - accuracy: 0.3671 - val_loss: 1.9431 - val_accuracy: 0.2300\n",
      "Epoch 345/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5291 - accuracy: 0.3686 - val_loss: 1.9443 - val_accuracy: 0.2567\n",
      "Epoch 346/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5301 - accuracy: 0.3700 - val_loss: 1.9314 - val_accuracy: 0.2267\n",
      "Epoch 347/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5277 - accuracy: 0.3800 - val_loss: 1.9199 - val_accuracy: 0.2200\n",
      "Epoch 348/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5284 - accuracy: 0.3643 - val_loss: 1.9294 - val_accuracy: 0.2167\n",
      "Epoch 349/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5281 - accuracy: 0.3700 - val_loss: 1.9273 - val_accuracy: 0.2133\n",
      "Epoch 350/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5282 - accuracy: 0.3657 - val_loss: 1.9311 - val_accuracy: 0.2300\n",
      "Epoch 351/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5264 - accuracy: 0.3757 - val_loss: 1.9309 - val_accuracy: 0.2333\n",
      "Epoch 352/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5283 - accuracy: 0.3729 - val_loss: 1.9282 - val_accuracy: 0.2300\n",
      "Epoch 353/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5256 - accuracy: 0.3657 - val_loss: 1.9422 - val_accuracy: 0.2300\n",
      "Epoch 354/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5279 - accuracy: 0.3700 - val_loss: 1.9350 - val_accuracy: 0.2167\n",
      "Epoch 355/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5261 - accuracy: 0.3600 - val_loss: 1.9553 - val_accuracy: 0.2267\n",
      "Epoch 356/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5260 - accuracy: 0.3700 - val_loss: 1.9442 - val_accuracy: 0.2433\n",
      "Epoch 357/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5259 - accuracy: 0.3743 - val_loss: 1.9355 - val_accuracy: 0.2267\n",
      "Epoch 358/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9494 - val_accuracy: 0.2233\n",
      "Epoch 359/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5251 - accuracy: 0.3729 - val_loss: 1.9450 - val_accuracy: 0.2133\n",
      "Epoch 360/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5232 - accuracy: 0.3743 - val_loss: 1.9454 - val_accuracy: 0.2233\n",
      "Epoch 361/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5232 - accuracy: 0.3686 - val_loss: 1.9485 - val_accuracy: 0.2300\n",
      "Epoch 362/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5240 - accuracy: 0.3643 - val_loss: 1.9508 - val_accuracy: 0.2267\n",
      "Epoch 363/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5215 - accuracy: 0.3757 - val_loss: 1.9527 - val_accuracy: 0.2333\n",
      "Epoch 364/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5230 - accuracy: 0.3643 - val_loss: 1.9381 - val_accuracy: 0.2300\n",
      "Epoch 365/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5224 - accuracy: 0.3771 - val_loss: 1.9524 - val_accuracy: 0.2267\n",
      "Epoch 366/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5222 - accuracy: 0.3686 - val_loss: 1.9406 - val_accuracy: 0.2133\n",
      "Epoch 367/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5221 - accuracy: 0.3757 - val_loss: 1.9567 - val_accuracy: 0.2300\n",
      "Epoch 368/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5206 - accuracy: 0.3786 - val_loss: 1.9551 - val_accuracy: 0.2367\n",
      "Epoch 369/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5207 - accuracy: 0.3629 - val_loss: 1.9321 - val_accuracy: 0.2367\n",
      "Epoch 370/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5200 - accuracy: 0.3757 - val_loss: 1.9534 - val_accuracy: 0.2400\n",
      "Epoch 371/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5209 - accuracy: 0.3671 - val_loss: 1.9508 - val_accuracy: 0.2233\n",
      "Epoch 372/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5195 - accuracy: 0.3729 - val_loss: 1.9590 - val_accuracy: 0.2333\n",
      "Epoch 373/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5205 - accuracy: 0.3757 - val_loss: 1.9453 - val_accuracy: 0.2133\n",
      "Epoch 374/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5197 - accuracy: 0.3686 - val_loss: 1.9514 - val_accuracy: 0.2267\n",
      "Epoch 375/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5181 - accuracy: 0.3843 - val_loss: 1.9386 - val_accuracy: 0.2267\n",
      "Epoch 376/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5182 - accuracy: 0.3800 - val_loss: 1.9487 - val_accuracy: 0.2167\n",
      "Epoch 377/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5170 - accuracy: 0.3743 - val_loss: 1.9760 - val_accuracy: 0.2267\n",
      "Epoch 378/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5182 - accuracy: 0.3743 - val_loss: 1.9761 - val_accuracy: 0.2367\n",
      "Epoch 379/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5188 - accuracy: 0.3700 - val_loss: 1.9516 - val_accuracy: 0.2367\n",
      "Epoch 380/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5166 - accuracy: 0.3671 - val_loss: 1.9602 - val_accuracy: 0.2567\n",
      "Epoch 381/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5180 - accuracy: 0.3786 - val_loss: 1.9711 - val_accuracy: 0.2167\n",
      "Epoch 382/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5161 - accuracy: 0.3743 - val_loss: 1.9585 - val_accuracy: 0.2267\n",
      "Epoch 383/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5155 - accuracy: 0.3700 - val_loss: 1.9714 - val_accuracy: 0.2433\n",
      "Epoch 384/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5164 - accuracy: 0.3771 - val_loss: 1.9509 - val_accuracy: 0.2233\n",
      "Epoch 385/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5163 - accuracy: 0.3743 - val_loss: 1.9579 - val_accuracy: 0.2267\n",
      "Epoch 386/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.5156 - accuracy: 0.3714 - val_loss: 1.9502 - val_accuracy: 0.2333\n",
      "Epoch 387/1000\n",
      "700/700 [==============================] - 0s 94us/step - loss: 1.5153 - accuracy: 0.3743 - val_loss: 1.9578 - val_accuracy: 0.2300\n",
      "Epoch 388/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5143 - accuracy: 0.3714 - val_loss: 1.9668 - val_accuracy: 0.2467\n",
      "Epoch 389/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5158 - accuracy: 0.3800 - val_loss: 1.9490 - val_accuracy: 0.2267\n",
      "Epoch 390/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5125 - accuracy: 0.3671 - val_loss: 1.9572 - val_accuracy: 0.2400\n",
      "Epoch 391/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5132 - accuracy: 0.3757 - val_loss: 1.9539 - val_accuracy: 0.2367\n",
      "Epoch 392/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5137 - accuracy: 0.3714 - val_loss: 1.9599 - val_accuracy: 0.2233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5137 - accuracy: 0.3757 - val_loss: 1.9730 - val_accuracy: 0.2233\n",
      "Epoch 394/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5136 - accuracy: 0.3757 - val_loss: 1.9565 - val_accuracy: 0.2267\n",
      "Epoch 395/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5132 - accuracy: 0.3771 - val_loss: 1.9565 - val_accuracy: 0.2167\n",
      "Epoch 396/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5124 - accuracy: 0.3771 - val_loss: 1.9619 - val_accuracy: 0.2167\n",
      "Epoch 397/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5111 - accuracy: 0.3857 - val_loss: 1.9755 - val_accuracy: 0.2367\n",
      "Epoch 398/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5124 - accuracy: 0.3643 - val_loss: 1.9588 - val_accuracy: 0.2200\n",
      "Epoch 399/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5107 - accuracy: 0.3743 - val_loss: 1.9904 - val_accuracy: 0.2333\n",
      "Epoch 400/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5113 - accuracy: 0.3643 - val_loss: 1.9599 - val_accuracy: 0.2167\n",
      "Epoch 401/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5109 - accuracy: 0.3657 - val_loss: 1.9595 - val_accuracy: 0.2267\n",
      "Epoch 402/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5086 - accuracy: 0.3771 - val_loss: 1.9650 - val_accuracy: 0.2233\n",
      "Epoch 403/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5068 - accuracy: 0.3843 - val_loss: 1.9968 - val_accuracy: 0.2200\n",
      "Epoch 404/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5085 - accuracy: 0.3743 - val_loss: 1.9680 - val_accuracy: 0.2333\n",
      "Epoch 405/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5074 - accuracy: 0.3800 - val_loss: 1.9833 - val_accuracy: 0.2300\n",
      "Epoch 406/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5085 - accuracy: 0.3771 - val_loss: 1.9756 - val_accuracy: 0.2200\n",
      "Epoch 407/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5080 - accuracy: 0.3714 - val_loss: 1.9815 - val_accuracy: 0.2267\n",
      "Epoch 408/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.5077 - accuracy: 0.3757 - val_loss: 1.9711 - val_accuracy: 0.2267\n",
      "Epoch 409/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5040 - accuracy: 0.3700 - val_loss: 1.9807 - val_accuracy: 0.2367\n",
      "Epoch 410/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5058 - accuracy: 0.3771 - val_loss: 1.9611 - val_accuracy: 0.2267\n",
      "Epoch 411/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.5056 - accuracy: 0.3714 - val_loss: 1.9846 - val_accuracy: 0.2300\n",
      "Epoch 412/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5048 - accuracy: 0.3843 - val_loss: 1.9728 - val_accuracy: 0.2233\n",
      "Epoch 413/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.5033 - accuracy: 0.3771 - val_loss: 1.9781 - val_accuracy: 0.2333\n",
      "Epoch 414/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5043 - accuracy: 0.3786 - val_loss: 1.9881 - val_accuracy: 0.2333\n",
      "Epoch 415/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5015 - accuracy: 0.3786 - val_loss: 1.9798 - val_accuracy: 0.2333\n",
      "Epoch 416/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.5031 - accuracy: 0.3843 - val_loss: 1.9929 - val_accuracy: 0.2267\n",
      "Epoch 417/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5032 - accuracy: 0.3786 - val_loss: 1.9828 - val_accuracy: 0.2200\n",
      "Epoch 418/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5016 - accuracy: 0.3871 - val_loss: 1.9756 - val_accuracy: 0.2333\n",
      "Epoch 419/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5019 - accuracy: 0.3786 - val_loss: 1.9663 - val_accuracy: 0.2200\n",
      "Epoch 420/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5015 - accuracy: 0.3800 - val_loss: 1.9912 - val_accuracy: 0.2300\n",
      "Epoch 421/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5011 - accuracy: 0.3829 - val_loss: 1.9693 - val_accuracy: 0.2433\n",
      "Epoch 422/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.5004 - accuracy: 0.3743 - val_loss: 1.9759 - val_accuracy: 0.2433\n",
      "Epoch 423/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.5003 - accuracy: 0.3814 - val_loss: 1.9815 - val_accuracy: 0.2333\n",
      "Epoch 424/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.5001 - accuracy: 0.3757 - val_loss: 1.9681 - val_accuracy: 0.2200\n",
      "Epoch 425/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4991 - accuracy: 0.3886 - val_loss: 1.9619 - val_accuracy: 0.2400\n",
      "Epoch 426/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4984 - accuracy: 0.3914 - val_loss: 1.9803 - val_accuracy: 0.2167\n",
      "Epoch 427/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4983 - accuracy: 0.3814 - val_loss: 1.9858 - val_accuracy: 0.2533\n",
      "Epoch 428/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4984 - accuracy: 0.3843 - val_loss: 2.0113 - val_accuracy: 0.2300\n",
      "Epoch 429/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4982 - accuracy: 0.3771 - val_loss: 1.9701 - val_accuracy: 0.2300\n",
      "Epoch 430/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4977 - accuracy: 0.3814 - val_loss: 1.9836 - val_accuracy: 0.2467\n",
      "Epoch 431/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4990 - accuracy: 0.3786 - val_loss: 1.9920 - val_accuracy: 0.2333\n",
      "Epoch 432/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4974 - accuracy: 0.3843 - val_loss: 1.9780 - val_accuracy: 0.2233\n",
      "Epoch 433/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4967 - accuracy: 0.3814 - val_loss: 1.9880 - val_accuracy: 0.2367\n",
      "Epoch 434/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4976 - accuracy: 0.3743 - val_loss: 1.9917 - val_accuracy: 0.2233\n",
      "Epoch 435/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4957 - accuracy: 0.3900 - val_loss: 1.9837 - val_accuracy: 0.2267\n",
      "Epoch 436/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4975 - accuracy: 0.3843 - val_loss: 1.9691 - val_accuracy: 0.2233\n",
      "Epoch 437/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4957 - accuracy: 0.3943 - val_loss: 1.9995 - val_accuracy: 0.2200\n",
      "Epoch 438/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4948 - accuracy: 0.3857 - val_loss: 1.9635 - val_accuracy: 0.2300\n",
      "Epoch 439/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4946 - accuracy: 0.3771 - val_loss: 1.9794 - val_accuracy: 0.2233\n",
      "Epoch 440/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4960 - accuracy: 0.3800 - val_loss: 1.9815 - val_accuracy: 0.2300\n",
      "Epoch 441/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4951 - accuracy: 0.3886 - val_loss: 1.9841 - val_accuracy: 0.2300\n",
      "Epoch 442/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4944 - accuracy: 0.3829 - val_loss: 1.9982 - val_accuracy: 0.2233\n",
      "Epoch 443/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4937 - accuracy: 0.3857 - val_loss: 1.9936 - val_accuracy: 0.2400\n",
      "Epoch 444/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4946 - accuracy: 0.3829 - val_loss: 1.9965 - val_accuracy: 0.2233\n",
      "Epoch 445/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4942 - accuracy: 0.3829 - val_loss: 2.0001 - val_accuracy: 0.2300\n",
      "Epoch 446/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4931 - accuracy: 0.3886 - val_loss: 2.0088 - val_accuracy: 0.2267\n",
      "Epoch 447/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4926 - accuracy: 0.3800 - val_loss: 2.0223 - val_accuracy: 0.2300\n",
      "Epoch 448/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4927 - accuracy: 0.3843 - val_loss: 1.9971 - val_accuracy: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4918 - accuracy: 0.3886 - val_loss: 2.0059 - val_accuracy: 0.2333\n",
      "Epoch 450/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4929 - accuracy: 0.3843 - val_loss: 1.9975 - val_accuracy: 0.2233\n",
      "Epoch 451/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4919 - accuracy: 0.3843 - val_loss: 2.0043 - val_accuracy: 0.2233\n",
      "Epoch 452/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4908 - accuracy: 0.3857 - val_loss: 1.9997 - val_accuracy: 0.2300\n",
      "Epoch 453/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4910 - accuracy: 0.3871 - val_loss: 1.9943 - val_accuracy: 0.2333\n",
      "Epoch 454/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4908 - accuracy: 0.3871 - val_loss: 2.0016 - val_accuracy: 0.2333\n",
      "Epoch 455/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4907 - accuracy: 0.3843 - val_loss: 1.9913 - val_accuracy: 0.2233\n",
      "Epoch 456/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4898 - accuracy: 0.3786 - val_loss: 1.9959 - val_accuracy: 0.2467\n",
      "Epoch 457/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4899 - accuracy: 0.3871 - val_loss: 2.0019 - val_accuracy: 0.2333\n",
      "Epoch 458/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4902 - accuracy: 0.3857 - val_loss: 1.9970 - val_accuracy: 0.2267\n",
      "Epoch 459/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4881 - accuracy: 0.3943 - val_loss: 1.9948 - val_accuracy: 0.2433\n",
      "Epoch 460/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4900 - accuracy: 0.3886 - val_loss: 2.0062 - val_accuracy: 0.2300\n",
      "Epoch 461/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4883 - accuracy: 0.3957 - val_loss: 2.0089 - val_accuracy: 0.2300\n",
      "Epoch 462/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4883 - accuracy: 0.3900 - val_loss: 1.9980 - val_accuracy: 0.2267\n",
      "Epoch 463/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4872 - accuracy: 0.3857 - val_loss: 2.0059 - val_accuracy: 0.2467\n",
      "Epoch 464/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 1.9923 - val_accuracy: 0.2333\n",
      "Epoch 465/1000\n",
      "700/700 [==============================] - 0s 81us/step - loss: 1.4877 - accuracy: 0.3900 - val_loss: 2.0023 - val_accuracy: 0.2233\n",
      "Epoch 466/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4871 - accuracy: 0.3757 - val_loss: 2.0065 - val_accuracy: 0.2267\n",
      "Epoch 467/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4873 - accuracy: 0.3871 - val_loss: 2.0133 - val_accuracy: 0.2300\n",
      "Epoch 468/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4865 - accuracy: 0.3829 - val_loss: 1.9941 - val_accuracy: 0.2267\n",
      "Epoch 469/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4859 - accuracy: 0.3871 - val_loss: 2.0429 - val_accuracy: 0.2333\n",
      "Epoch 470/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4871 - accuracy: 0.3871 - val_loss: 2.0173 - val_accuracy: 0.2233\n",
      "Epoch 471/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4859 - accuracy: 0.3957 - val_loss: 2.0124 - val_accuracy: 0.2267\n",
      "Epoch 472/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4845 - accuracy: 0.3971 - val_loss: 2.0157 - val_accuracy: 0.2367\n",
      "Epoch 473/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4850 - accuracy: 0.3914 - val_loss: 2.0205 - val_accuracy: 0.2367\n",
      "Epoch 474/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4838 - accuracy: 0.3900 - val_loss: 2.0030 - val_accuracy: 0.2267\n",
      "Epoch 475/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4842 - accuracy: 0.3900 - val_loss: 2.0116 - val_accuracy: 0.2233\n",
      "Epoch 476/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4835 - accuracy: 0.3900 - val_loss: 2.0127 - val_accuracy: 0.2267\n",
      "Epoch 477/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4839 - accuracy: 0.3900 - val_loss: 2.0173 - val_accuracy: 0.2267\n",
      "Epoch 478/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4838 - accuracy: 0.3929 - val_loss: 2.0124 - val_accuracy: 0.2333\n",
      "Epoch 479/1000\n",
      "700/700 [==============================] - 0s 80us/step - loss: 1.4833 - accuracy: 0.3900 - val_loss: 2.0080 - val_accuracy: 0.2300\n",
      "Epoch 480/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4824 - accuracy: 0.3957 - val_loss: 2.0183 - val_accuracy: 0.2367\n",
      "Epoch 481/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4821 - accuracy: 0.3871 - val_loss: 2.0288 - val_accuracy: 0.2400\n",
      "Epoch 482/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4810 - accuracy: 0.3986 - val_loss: 2.0248 - val_accuracy: 0.2300\n",
      "Epoch 483/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4821 - accuracy: 0.4000 - val_loss: 2.0233 - val_accuracy: 0.2367\n",
      "Epoch 484/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4815 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2400\n",
      "Epoch 485/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4811 - accuracy: 0.4029 - val_loss: 2.0243 - val_accuracy: 0.2300\n",
      "Epoch 486/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4808 - accuracy: 0.3857 - val_loss: 2.0156 - val_accuracy: 0.2467\n",
      "Epoch 487/1000\n",
      "700/700 [==============================] - 0s 83us/step - loss: 1.4811 - accuracy: 0.3957 - val_loss: 2.0159 - val_accuracy: 0.2500\n",
      "Epoch 488/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4808 - accuracy: 0.3914 - val_loss: 2.0247 - val_accuracy: 0.2500\n",
      "Epoch 489/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4804 - accuracy: 0.3886 - val_loss: 2.0107 - val_accuracy: 0.2267\n",
      "Epoch 490/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4809 - accuracy: 0.3900 - val_loss: 2.0066 - val_accuracy: 0.2333\n",
      "Epoch 491/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4808 - accuracy: 0.3871 - val_loss: 2.0321 - val_accuracy: 0.2300\n",
      "Epoch 492/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4800 - accuracy: 0.3914 - val_loss: 2.0072 - val_accuracy: 0.2267\n",
      "Epoch 493/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4799 - accuracy: 0.4014 - val_loss: 2.0164 - val_accuracy: 0.2333\n",
      "Epoch 494/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4802 - accuracy: 0.3900 - val_loss: 2.0155 - val_accuracy: 0.2233\n",
      "Epoch 495/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4792 - accuracy: 0.4029 - val_loss: 2.0383 - val_accuracy: 0.2333\n",
      "Epoch 496/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4786 - accuracy: 0.3857 - val_loss: 2.0199 - val_accuracy: 0.2433\n",
      "Epoch 497/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4773 - accuracy: 0.3929 - val_loss: 2.0210 - val_accuracy: 0.2467\n",
      "Epoch 498/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4763 - accuracy: 0.3886 - val_loss: 2.0652 - val_accuracy: 0.2367\n",
      "Epoch 499/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4775 - accuracy: 0.4014 - val_loss: 2.0415 - val_accuracy: 0.2367\n",
      "Epoch 500/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4780 - accuracy: 0.3929 - val_loss: 2.0389 - val_accuracy: 0.2367\n",
      "Epoch 501/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4782 - accuracy: 0.4000 - val_loss: 2.0378 - val_accuracy: 0.2300\n",
      "Epoch 502/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4760 - accuracy: 0.3943 - val_loss: 2.0391 - val_accuracy: 0.2267\n",
      "Epoch 503/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4766 - accuracy: 0.3957 - val_loss: 2.0315 - val_accuracy: 0.2267\n",
      "Epoch 504/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4757 - accuracy: 0.3971 - val_loss: 2.0373 - val_accuracy: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 505/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4754 - accuracy: 0.3957 - val_loss: 2.0319 - val_accuracy: 0.2400\n",
      "Epoch 506/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4754 - accuracy: 0.3986 - val_loss: 2.0256 - val_accuracy: 0.2300\n",
      "Epoch 507/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4769 - accuracy: 0.3986 - val_loss: 2.0355 - val_accuracy: 0.2233\n",
      "Epoch 508/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4750 - accuracy: 0.3900 - val_loss: 2.0376 - val_accuracy: 0.2267\n",
      "Epoch 509/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4744 - accuracy: 0.3943 - val_loss: 2.0544 - val_accuracy: 0.2333\n",
      "Epoch 510/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4745 - accuracy: 0.3914 - val_loss: 2.0370 - val_accuracy: 0.2233\n",
      "Epoch 511/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4737 - accuracy: 0.4029 - val_loss: 2.0263 - val_accuracy: 0.2267\n",
      "Epoch 512/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4739 - accuracy: 0.3971 - val_loss: 2.0206 - val_accuracy: 0.2467\n",
      "Epoch 513/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4732 - accuracy: 0.3986 - val_loss: 2.0255 - val_accuracy: 0.2433\n",
      "Epoch 514/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4727 - accuracy: 0.4000 - val_loss: 2.0425 - val_accuracy: 0.2267\n",
      "Epoch 515/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4734 - accuracy: 0.4014 - val_loss: 2.0394 - val_accuracy: 0.2300\n",
      "Epoch 516/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4741 - accuracy: 0.3957 - val_loss: 2.0433 - val_accuracy: 0.2267\n",
      "Epoch 517/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4706 - accuracy: 0.3929 - val_loss: 2.0516 - val_accuracy: 0.2500\n",
      "Epoch 518/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4740 - accuracy: 0.4000 - val_loss: 2.0528 - val_accuracy: 0.2267\n",
      "Epoch 519/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4727 - accuracy: 0.4043 - val_loss: 2.0387 - val_accuracy: 0.2300\n",
      "Epoch 520/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4718 - accuracy: 0.3957 - val_loss: 2.0482 - val_accuracy: 0.2400\n",
      "Epoch 521/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4713 - accuracy: 0.4129 - val_loss: 2.0242 - val_accuracy: 0.2333\n",
      "Epoch 522/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4725 - accuracy: 0.3986 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 523/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4721 - accuracy: 0.3929 - val_loss: 2.0464 - val_accuracy: 0.2267\n",
      "Epoch 524/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4711 - accuracy: 0.3986 - val_loss: 2.0381 - val_accuracy: 0.2333\n",
      "Epoch 525/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4696 - accuracy: 0.4000 - val_loss: 2.0453 - val_accuracy: 0.2467\n",
      "Epoch 526/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4711 - accuracy: 0.4029 - val_loss: 2.0409 - val_accuracy: 0.2267\n",
      "Epoch 527/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4702 - accuracy: 0.3929 - val_loss: 2.0426 - val_accuracy: 0.2300\n",
      "Epoch 528/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4694 - accuracy: 0.4029 - val_loss: 2.0468 - val_accuracy: 0.2267\n",
      "Epoch 529/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4681 - accuracy: 0.3943 - val_loss: 2.0523 - val_accuracy: 0.2267\n",
      "Epoch 530/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4686 - accuracy: 0.4000 - val_loss: 2.0623 - val_accuracy: 0.2267\n",
      "Epoch 531/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4689 - accuracy: 0.3957 - val_loss: 2.0410 - val_accuracy: 0.2433\n",
      "Epoch 532/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4690 - accuracy: 0.4014 - val_loss: 2.0542 - val_accuracy: 0.2433\n",
      "Epoch 533/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4685 - accuracy: 0.4000 - val_loss: 2.0491 - val_accuracy: 0.2300\n",
      "Epoch 534/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4688 - accuracy: 0.3971 - val_loss: 2.0431 - val_accuracy: 0.2300\n",
      "Epoch 535/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4673 - accuracy: 0.4043 - val_loss: 2.0739 - val_accuracy: 0.2433\n",
      "Epoch 536/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4671 - accuracy: 0.4043 - val_loss: 2.0705 - val_accuracy: 0.2267\n",
      "Epoch 537/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4676 - accuracy: 0.4029 - val_loss: 2.0477 - val_accuracy: 0.2300\n",
      "Epoch 538/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4672 - accuracy: 0.3957 - val_loss: 2.0574 - val_accuracy: 0.2367\n",
      "Epoch 539/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4691 - accuracy: 0.3943 - val_loss: 2.0508 - val_accuracy: 0.2267\n",
      "Epoch 540/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4678 - accuracy: 0.4014 - val_loss: 2.0620 - val_accuracy: 0.2267\n",
      "Epoch 541/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4667 - accuracy: 0.4014 - val_loss: 2.0590 - val_accuracy: 0.2267\n",
      "Epoch 542/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4665 - accuracy: 0.4057 - val_loss: 2.0668 - val_accuracy: 0.2433\n",
      "Epoch 543/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4670 - accuracy: 0.4000 - val_loss: 2.0490 - val_accuracy: 0.2333\n",
      "Epoch 544/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4657 - accuracy: 0.3943 - val_loss: 2.0425 - val_accuracy: 0.2367\n",
      "Epoch 545/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4665 - accuracy: 0.4014 - val_loss: 2.0537 - val_accuracy: 0.2300\n",
      "Epoch 546/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4635 - accuracy: 0.4000 - val_loss: 2.0713 - val_accuracy: 0.2533\n",
      "Epoch 547/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4657 - accuracy: 0.4000 - val_loss: 2.0779 - val_accuracy: 0.2400\n",
      "Epoch 548/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4643 - accuracy: 0.3971 - val_loss: 2.0494 - val_accuracy: 0.2300\n",
      "Epoch 549/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4647 - accuracy: 0.4043 - val_loss: 2.0443 - val_accuracy: 0.2333\n",
      "Epoch 550/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4638 - accuracy: 0.4000 - val_loss: 2.0608 - val_accuracy: 0.2300\n",
      "Epoch 551/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4647 - accuracy: 0.4000 - val_loss: 2.0584 - val_accuracy: 0.2300\n",
      "Epoch 552/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4632 - accuracy: 0.4086 - val_loss: 2.0582 - val_accuracy: 0.2333\n",
      "Epoch 553/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4654 - accuracy: 0.4000 - val_loss: 2.0563 - val_accuracy: 0.2300\n",
      "Epoch 554/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4630 - accuracy: 0.3986 - val_loss: 2.0678 - val_accuracy: 0.2300\n",
      "Epoch 555/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4637 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2400\n",
      "Epoch 556/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4621 - accuracy: 0.4000 - val_loss: 2.0621 - val_accuracy: 0.2467\n",
      "Epoch 557/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4614 - accuracy: 0.4114 - val_loss: 2.0831 - val_accuracy: 0.2500\n",
      "Epoch 558/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4631 - accuracy: 0.4029 - val_loss: 2.0614 - val_accuracy: 0.2333\n",
      "Epoch 559/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4614 - accuracy: 0.4029 - val_loss: 2.0657 - val_accuracy: 0.2533\n",
      "Epoch 560/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4612 - accuracy: 0.4014 - val_loss: 2.0698 - val_accuracy: 0.2567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 561/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4623 - accuracy: 0.4100 - val_loss: 2.0637 - val_accuracy: 0.2267\n",
      "Epoch 562/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4619 - accuracy: 0.4029 - val_loss: 2.0546 - val_accuracy: 0.2300\n",
      "Epoch 563/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4613 - accuracy: 0.4000 - val_loss: 2.0600 - val_accuracy: 0.2267\n",
      "Epoch 564/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4611 - accuracy: 0.4071 - val_loss: 2.0795 - val_accuracy: 0.2300\n",
      "Epoch 565/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4603 - accuracy: 0.4043 - val_loss: 2.0619 - val_accuracy: 0.2333\n",
      "Epoch 566/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4620 - accuracy: 0.4100 - val_loss: 2.0743 - val_accuracy: 0.2300\n",
      "Epoch 567/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4599 - accuracy: 0.4171 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 568/1000\n",
      "700/700 [==============================] - 0s 71us/step - loss: 1.4598 - accuracy: 0.4057 - val_loss: 2.0765 - val_accuracy: 0.2433\n",
      "Epoch 569/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4594 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2533\n",
      "Epoch 570/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4586 - accuracy: 0.4114 - val_loss: 2.0794 - val_accuracy: 0.2333\n",
      "Epoch 571/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4588 - accuracy: 0.4043 - val_loss: 2.0763 - val_accuracy: 0.2300\n",
      "Epoch 572/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4580 - accuracy: 0.4014 - val_loss: 2.0652 - val_accuracy: 0.2333\n",
      "Epoch 573/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0851 - val_accuracy: 0.2533\n",
      "Epoch 574/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4597 - accuracy: 0.4043 - val_loss: 2.0670 - val_accuracy: 0.2500\n",
      "Epoch 575/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4597 - accuracy: 0.4114 - val_loss: 2.0723 - val_accuracy: 0.2267\n",
      "Epoch 576/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4586 - accuracy: 0.3957 - val_loss: 2.0748 - val_accuracy: 0.2300\n",
      "Epoch 577/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4583 - accuracy: 0.4014 - val_loss: 2.0725 - val_accuracy: 0.2300\n",
      "Epoch 578/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4577 - accuracy: 0.4071 - val_loss: 2.0727 - val_accuracy: 0.2367\n",
      "Epoch 579/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4584 - accuracy: 0.4057 - val_loss: 2.0700 - val_accuracy: 0.2267\n",
      "Epoch 580/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4574 - accuracy: 0.4086 - val_loss: 2.0834 - val_accuracy: 0.2367\n",
      "Epoch 581/1000\n",
      "700/700 [==============================] - 0s 89us/step - loss: 1.4570 - accuracy: 0.4071 - val_loss: 2.0783 - val_accuracy: 0.2567\n",
      "Epoch 582/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4569 - accuracy: 0.4071 - val_loss: 2.0819 - val_accuracy: 0.2267\n",
      "Epoch 583/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4563 - accuracy: 0.4014 - val_loss: 2.0840 - val_accuracy: 0.2267\n",
      "Epoch 584/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4571 - accuracy: 0.4071 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 585/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4558 - accuracy: 0.4100 - val_loss: 2.0865 - val_accuracy: 0.2300\n",
      "Epoch 586/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4549 - accuracy: 0.4043 - val_loss: 2.0878 - val_accuracy: 0.2500\n",
      "Epoch 587/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4573 - accuracy: 0.4114 - val_loss: 2.0871 - val_accuracy: 0.2333\n",
      "Epoch 588/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4560 - accuracy: 0.4043 - val_loss: 2.0902 - val_accuracy: 0.2300\n",
      "Epoch 589/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4553 - accuracy: 0.4057 - val_loss: 2.0906 - val_accuracy: 0.2267\n",
      "Epoch 590/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4553 - accuracy: 0.4014 - val_loss: 2.0836 - val_accuracy: 0.2300\n",
      "Epoch 591/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4554 - accuracy: 0.4086 - val_loss: 2.0946 - val_accuracy: 0.2267\n",
      "Epoch 592/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4544 - accuracy: 0.4086 - val_loss: 2.0885 - val_accuracy: 0.2333\n",
      "Epoch 593/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4546 - accuracy: 0.4057 - val_loss: 2.0817 - val_accuracy: 0.2267\n",
      "Epoch 594/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4540 - accuracy: 0.4129 - val_loss: 2.0828 - val_accuracy: 0.2333\n",
      "Epoch 595/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4543 - accuracy: 0.4057 - val_loss: 2.0905 - val_accuracy: 0.2433\n",
      "Epoch 596/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4537 - accuracy: 0.4129 - val_loss: 2.0782 - val_accuracy: 0.2300\n",
      "Epoch 597/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0808 - val_accuracy: 0.2500\n",
      "Epoch 598/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4537 - accuracy: 0.3986 - val_loss: 2.0903 - val_accuracy: 0.2267\n",
      "Epoch 599/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4541 - accuracy: 0.4043 - val_loss: 2.0796 - val_accuracy: 0.2333\n",
      "Epoch 600/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4525 - accuracy: 0.4143 - val_loss: 2.0989 - val_accuracy: 0.2300\n",
      "Epoch 601/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4523 - accuracy: 0.4129 - val_loss: 2.0981 - val_accuracy: 0.2433\n",
      "Epoch 602/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4526 - accuracy: 0.4029 - val_loss: 2.0933 - val_accuracy: 0.2333\n",
      "Epoch 603/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4527 - accuracy: 0.4114 - val_loss: 2.0824 - val_accuracy: 0.2400\n",
      "Epoch 604/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4525 - accuracy: 0.4029 - val_loss: 2.0809 - val_accuracy: 0.2433\n",
      "Epoch 605/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4516 - accuracy: 0.4057 - val_loss: 2.0888 - val_accuracy: 0.2367\n",
      "Epoch 606/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4517 - accuracy: 0.4100 - val_loss: 2.0793 - val_accuracy: 0.2333\n",
      "Epoch 607/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4518 - accuracy: 0.4100 - val_loss: 2.0931 - val_accuracy: 0.2300\n",
      "Epoch 608/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4515 - accuracy: 0.4071 - val_loss: 2.0832 - val_accuracy: 0.2367\n",
      "Epoch 609/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4500 - accuracy: 0.4157 - val_loss: 2.0998 - val_accuracy: 0.2567\n",
      "Epoch 610/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4507 - accuracy: 0.4129 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 611/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4508 - accuracy: 0.4129 - val_loss: 2.0975 - val_accuracy: 0.2367\n",
      "Epoch 612/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4506 - accuracy: 0.4086 - val_loss: 2.0951 - val_accuracy: 0.2433\n",
      "Epoch 613/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4505 - accuracy: 0.4086 - val_loss: 2.0964 - val_accuracy: 0.2300\n",
      "Epoch 614/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4496 - accuracy: 0.4129 - val_loss: 2.1080 - val_accuracy: 0.2500\n",
      "Epoch 615/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4502 - accuracy: 0.4129 - val_loss: 2.0887 - val_accuracy: 0.2533\n",
      "Epoch 616/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4495 - accuracy: 0.4129 - val_loss: 2.1144 - val_accuracy: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 617/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4480 - accuracy: 0.4157 - val_loss: 2.1039 - val_accuracy: 0.2533\n",
      "Epoch 618/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4491 - accuracy: 0.4014 - val_loss: 2.0963 - val_accuracy: 0.2400\n",
      "Epoch 619/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4479 - accuracy: 0.4114 - val_loss: 2.1056 - val_accuracy: 0.2333\n",
      "Epoch 620/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4488 - accuracy: 0.4171 - val_loss: 2.0924 - val_accuracy: 0.2300\n",
      "Epoch 621/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4487 - accuracy: 0.4129 - val_loss: 2.1158 - val_accuracy: 0.2333\n",
      "Epoch 622/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4476 - accuracy: 0.4114 - val_loss: 2.1155 - val_accuracy: 0.2367\n",
      "Epoch 623/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4471 - accuracy: 0.4186 - val_loss: 2.1097 - val_accuracy: 0.2267\n",
      "Epoch 624/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4480 - accuracy: 0.4171 - val_loss: 2.1088 - val_accuracy: 0.2367\n",
      "Epoch 625/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4479 - accuracy: 0.4029 - val_loss: 2.1142 - val_accuracy: 0.2367\n",
      "Epoch 626/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4471 - accuracy: 0.4086 - val_loss: 2.0894 - val_accuracy: 0.2367\n",
      "Epoch 627/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4478 - accuracy: 0.4257 - val_loss: 2.1022 - val_accuracy: 0.2333\n",
      "Epoch 628/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4459 - accuracy: 0.4157 - val_loss: 2.0855 - val_accuracy: 0.2400\n",
      "Epoch 629/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4475 - accuracy: 0.4100 - val_loss: 2.1012 - val_accuracy: 0.2333\n",
      "Epoch 630/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4460 - accuracy: 0.4114 - val_loss: 2.0909 - val_accuracy: 0.2333\n",
      "Epoch 631/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4468 - accuracy: 0.4114 - val_loss: 2.1271 - val_accuracy: 0.2400\n",
      "Epoch 632/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4467 - accuracy: 0.4086 - val_loss: 2.1177 - val_accuracy: 0.2400\n",
      "Epoch 633/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4455 - accuracy: 0.4143 - val_loss: 2.1269 - val_accuracy: 0.2367\n",
      "Epoch 634/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4457 - accuracy: 0.4129 - val_loss: 2.1139 - val_accuracy: 0.2333\n",
      "Epoch 635/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4444 - accuracy: 0.4071 - val_loss: 2.1061 - val_accuracy: 0.2567\n",
      "Epoch 636/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4463 - accuracy: 0.4129 - val_loss: 2.1088 - val_accuracy: 0.2333\n",
      "Epoch 637/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4451 - accuracy: 0.4114 - val_loss: 2.1212 - val_accuracy: 0.2367\n",
      "Epoch 638/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4452 - accuracy: 0.4114 - val_loss: 2.1277 - val_accuracy: 0.2300\n",
      "Epoch 639/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4449 - accuracy: 0.4086 - val_loss: 2.1286 - val_accuracy: 0.2233\n",
      "Epoch 640/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4441 - accuracy: 0.4157 - val_loss: 2.0973 - val_accuracy: 0.2367\n",
      "Epoch 641/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4437 - accuracy: 0.4143 - val_loss: 2.1183 - val_accuracy: 0.2467\n",
      "Epoch 642/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4448 - accuracy: 0.4100 - val_loss: 2.1281 - val_accuracy: 0.2433\n",
      "Epoch 643/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4439 - accuracy: 0.4129 - val_loss: 2.1331 - val_accuracy: 0.2300\n",
      "Epoch 644/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4440 - accuracy: 0.4129 - val_loss: 2.1148 - val_accuracy: 0.2367\n",
      "Epoch 645/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4432 - accuracy: 0.4186 - val_loss: 2.1250 - val_accuracy: 0.2333\n",
      "Epoch 646/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4414 - accuracy: 0.4114 - val_loss: 2.1179 - val_accuracy: 0.2567\n",
      "Epoch 647/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4423 - accuracy: 0.4114 - val_loss: 2.1133 - val_accuracy: 0.2367\n",
      "Epoch 648/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4431 - accuracy: 0.4100 - val_loss: 2.1343 - val_accuracy: 0.2333\n",
      "Epoch 649/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4415 - accuracy: 0.4057 - val_loss: 2.1301 - val_accuracy: 0.2333\n",
      "Epoch 650/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4432 - accuracy: 0.4143 - val_loss: 2.1169 - val_accuracy: 0.2333\n",
      "Epoch 651/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4418 - accuracy: 0.4157 - val_loss: 2.1391 - val_accuracy: 0.2400\n",
      "Epoch 652/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4430 - accuracy: 0.4114 - val_loss: 2.1186 - val_accuracy: 0.2333\n",
      "Epoch 653/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4415 - accuracy: 0.4171 - val_loss: 2.1247 - val_accuracy: 0.2433\n",
      "Epoch 654/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4414 - accuracy: 0.4143 - val_loss: 2.1066 - val_accuracy: 0.2467\n",
      "Epoch 655/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4406 - accuracy: 0.4100 - val_loss: 2.1201 - val_accuracy: 0.2533\n",
      "Epoch 656/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4426 - accuracy: 0.4086 - val_loss: 2.1340 - val_accuracy: 0.2433\n",
      "Epoch 657/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4409 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2300\n",
      "Epoch 658/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4409 - accuracy: 0.4143 - val_loss: 2.1242 - val_accuracy: 0.2367\n",
      "Epoch 659/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4404 - accuracy: 0.4186 - val_loss: 2.1269 - val_accuracy: 0.2467\n",
      "Epoch 660/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4409 - accuracy: 0.4100 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 661/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4418 - accuracy: 0.4086 - val_loss: 2.1221 - val_accuracy: 0.2367\n",
      "Epoch 662/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4410 - accuracy: 0.4000 - val_loss: 2.1275 - val_accuracy: 0.2367\n",
      "Epoch 663/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4402 - accuracy: 0.4157 - val_loss: 2.1482 - val_accuracy: 0.2400\n",
      "Epoch 664/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4394 - accuracy: 0.4186 - val_loss: 2.1317 - val_accuracy: 0.2400\n",
      "Epoch 665/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4396 - accuracy: 0.4114 - val_loss: 2.1400 - val_accuracy: 0.2333\n",
      "Epoch 666/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4390 - accuracy: 0.4200 - val_loss: 2.1294 - val_accuracy: 0.2533\n",
      "Epoch 667/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4406 - accuracy: 0.4114 - val_loss: 2.1217 - val_accuracy: 0.2367\n",
      "Epoch 668/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4375 - accuracy: 0.4157 - val_loss: 2.1405 - val_accuracy: 0.2567\n",
      "Epoch 669/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4382 - accuracy: 0.4157 - val_loss: 2.1450 - val_accuracy: 0.2333\n",
      "Epoch 670/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4393 - accuracy: 0.4171 - val_loss: 2.1303 - val_accuracy: 0.2333\n",
      "Epoch 671/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1282 - val_accuracy: 0.2533\n",
      "Epoch 672/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4382 - accuracy: 0.4100 - val_loss: 2.1405 - val_accuracy: 0.2367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 673/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4384 - accuracy: 0.4186 - val_loss: 2.1311 - val_accuracy: 0.2400\n",
      "Epoch 674/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4374 - accuracy: 0.4086 - val_loss: 2.1580 - val_accuracy: 0.2433\n",
      "Epoch 675/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4366 - accuracy: 0.4214 - val_loss: 2.1570 - val_accuracy: 0.2533\n",
      "Epoch 676/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1286 - val_accuracy: 0.2567\n",
      "Epoch 677/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4360 - accuracy: 0.4143 - val_loss: 2.1505 - val_accuracy: 0.2300\n",
      "Epoch 678/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4355 - accuracy: 0.4200 - val_loss: 2.1176 - val_accuracy: 0.2333\n",
      "Epoch 679/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4369 - accuracy: 0.4257 - val_loss: 2.1406 - val_accuracy: 0.2367\n",
      "Epoch 680/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4377 - accuracy: 0.4157 - val_loss: 2.1416 - val_accuracy: 0.2400\n",
      "Epoch 681/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4370 - accuracy: 0.4186 - val_loss: 2.1307 - val_accuracy: 0.2400\n",
      "Epoch 682/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4360 - accuracy: 0.4214 - val_loss: 2.1368 - val_accuracy: 0.2567\n",
      "Epoch 683/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4356 - accuracy: 0.4129 - val_loss: 2.1275 - val_accuracy: 0.2500\n",
      "Epoch 684/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4330 - accuracy: 0.4143 - val_loss: 2.1410 - val_accuracy: 0.2600\n",
      "Epoch 685/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4356 - accuracy: 0.4143 - val_loss: 2.1360 - val_accuracy: 0.2567\n",
      "Epoch 686/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4352 - accuracy: 0.4200 - val_loss: 2.1651 - val_accuracy: 0.2533\n",
      "Epoch 687/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4354 - accuracy: 0.4143 - val_loss: 2.1270 - val_accuracy: 0.2367\n",
      "Epoch 688/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4355 - accuracy: 0.4157 - val_loss: 2.1346 - val_accuracy: 0.2400\n",
      "Epoch 689/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4348 - accuracy: 0.4200 - val_loss: 2.1469 - val_accuracy: 0.2367\n",
      "Epoch 690/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4345 - accuracy: 0.4143 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 691/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4337 - accuracy: 0.4229 - val_loss: 2.1496 - val_accuracy: 0.2333\n",
      "Epoch 692/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4339 - accuracy: 0.4186 - val_loss: 2.1345 - val_accuracy: 0.2400\n",
      "Epoch 693/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4345 - accuracy: 0.4171 - val_loss: 2.1337 - val_accuracy: 0.2400\n",
      "Epoch 694/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4335 - accuracy: 0.4186 - val_loss: 2.1663 - val_accuracy: 0.2467\n",
      "Epoch 695/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4348 - accuracy: 0.4171 - val_loss: 2.1408 - val_accuracy: 0.2567\n",
      "Epoch 696/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4324 - accuracy: 0.4214 - val_loss: 2.1548 - val_accuracy: 0.2333\n",
      "Epoch 697/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4337 - accuracy: 0.4186 - val_loss: 2.1654 - val_accuracy: 0.2467\n",
      "Epoch 698/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4333 - accuracy: 0.4257 - val_loss: 2.1511 - val_accuracy: 0.2433\n",
      "Epoch 699/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4328 - accuracy: 0.4214 - val_loss: 2.1525 - val_accuracy: 0.2400\n",
      "Epoch 700/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4329 - accuracy: 0.4200 - val_loss: 2.1518 - val_accuracy: 0.2467\n",
      "Epoch 701/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4316 - accuracy: 0.4171 - val_loss: 2.1483 - val_accuracy: 0.2433\n",
      "Epoch 702/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4327 - accuracy: 0.4129 - val_loss: 2.1556 - val_accuracy: 0.2367\n",
      "Epoch 703/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4316 - accuracy: 0.4229 - val_loss: 2.1657 - val_accuracy: 0.2333\n",
      "Epoch 704/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4325 - accuracy: 0.4214 - val_loss: 2.1498 - val_accuracy: 0.2433\n",
      "Epoch 705/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4320 - accuracy: 0.4157 - val_loss: 2.1429 - val_accuracy: 0.2400\n",
      "Epoch 706/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4321 - accuracy: 0.4214 - val_loss: 2.1335 - val_accuracy: 0.2400\n",
      "Epoch 707/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4315 - accuracy: 0.4243 - val_loss: 2.1494 - val_accuracy: 0.2367\n",
      "Epoch 708/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4316 - accuracy: 0.4214 - val_loss: 2.1488 - val_accuracy: 0.2333\n",
      "Epoch 709/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4296 - accuracy: 0.4186 - val_loss: 2.1794 - val_accuracy: 0.2533\n",
      "Epoch 710/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4314 - accuracy: 0.4229 - val_loss: 2.1527 - val_accuracy: 0.2467\n",
      "Epoch 711/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4304 - accuracy: 0.4186 - val_loss: 2.1542 - val_accuracy: 0.2367\n",
      "Epoch 712/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4300 - accuracy: 0.4214 - val_loss: 2.1636 - val_accuracy: 0.2567\n",
      "Epoch 713/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4310 - accuracy: 0.4186 - val_loss: 2.1410 - val_accuracy: 0.2400\n",
      "Epoch 714/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4305 - accuracy: 0.4243 - val_loss: 2.1585 - val_accuracy: 0.2367\n",
      "Epoch 715/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4282 - accuracy: 0.4243 - val_loss: 2.1502 - val_accuracy: 0.2600\n",
      "Epoch 716/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4305 - accuracy: 0.4157 - val_loss: 2.1677 - val_accuracy: 0.2367\n",
      "Epoch 717/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4297 - accuracy: 0.4157 - val_loss: 2.1621 - val_accuracy: 0.2367\n",
      "Epoch 718/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4289 - accuracy: 0.4186 - val_loss: 2.1916 - val_accuracy: 0.2533\n",
      "Epoch 719/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4303 - accuracy: 0.4186 - val_loss: 2.1728 - val_accuracy: 0.2400\n",
      "Epoch 720/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4295 - accuracy: 0.4214 - val_loss: 2.1658 - val_accuracy: 0.2367\n",
      "Epoch 721/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4291 - accuracy: 0.4200 - val_loss: 2.1649 - val_accuracy: 0.2433\n",
      "Epoch 722/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4286 - accuracy: 0.4200 - val_loss: 2.1653 - val_accuracy: 0.2367\n",
      "Epoch 723/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4282 - accuracy: 0.4214 - val_loss: 2.1490 - val_accuracy: 0.2400\n",
      "Epoch 724/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4281 - accuracy: 0.4257 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 725/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4277 - accuracy: 0.4229 - val_loss: 2.1819 - val_accuracy: 0.2433\n",
      "Epoch 726/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4278 - accuracy: 0.4257 - val_loss: 2.1563 - val_accuracy: 0.2367\n",
      "Epoch 727/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4273 - accuracy: 0.4214 - val_loss: 2.1938 - val_accuracy: 0.2333\n",
      "Epoch 728/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4276 - accuracy: 0.4200 - val_loss: 2.1558 - val_accuracy: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4269 - accuracy: 0.4229 - val_loss: 2.1856 - val_accuracy: 0.2467\n",
      "Epoch 730/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4269 - accuracy: 0.4257 - val_loss: 2.1927 - val_accuracy: 0.2400\n",
      "Epoch 731/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4277 - accuracy: 0.4143 - val_loss: 2.1736 - val_accuracy: 0.2367\n",
      "Epoch 732/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4261 - accuracy: 0.4243 - val_loss: 2.1707 - val_accuracy: 0.2400\n",
      "Epoch 733/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4263 - accuracy: 0.4286 - val_loss: 2.1618 - val_accuracy: 0.2400\n",
      "Epoch 734/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4271 - accuracy: 0.4214 - val_loss: 2.1844 - val_accuracy: 0.2400\n",
      "Epoch 735/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4261 - accuracy: 0.4286 - val_loss: 2.1732 - val_accuracy: 0.2367\n",
      "Epoch 736/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4249 - accuracy: 0.4300 - val_loss: 2.1629 - val_accuracy: 0.2400\n",
      "Epoch 737/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4265 - accuracy: 0.4229 - val_loss: 2.1866 - val_accuracy: 0.2433\n",
      "Epoch 738/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4265 - accuracy: 0.4200 - val_loss: 2.1722 - val_accuracy: 0.2467\n",
      "Epoch 739/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4251 - accuracy: 0.4271 - val_loss: 2.1827 - val_accuracy: 0.2367\n",
      "Epoch 740/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4250 - accuracy: 0.4314 - val_loss: 2.1680 - val_accuracy: 0.2400\n",
      "Epoch 741/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4249 - accuracy: 0.4200 - val_loss: 2.1864 - val_accuracy: 0.2567\n",
      "Epoch 742/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4252 - accuracy: 0.4143 - val_loss: 2.1628 - val_accuracy: 0.2533\n",
      "Epoch 743/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4240 - accuracy: 0.4286 - val_loss: 2.1670 - val_accuracy: 0.2533\n",
      "Epoch 744/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4257 - accuracy: 0.4186 - val_loss: 2.1682 - val_accuracy: 0.2433\n",
      "Epoch 745/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4221 - accuracy: 0.4329 - val_loss: 2.1818 - val_accuracy: 0.2533\n",
      "Epoch 746/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4254 - accuracy: 0.4300 - val_loss: 2.1702 - val_accuracy: 0.2400\n",
      "Epoch 747/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4251 - accuracy: 0.4157 - val_loss: 2.1784 - val_accuracy: 0.2433\n",
      "Epoch 748/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4233 - accuracy: 0.4257 - val_loss: 2.2001 - val_accuracy: 0.2600\n",
      "Epoch 749/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4222 - accuracy: 0.4271 - val_loss: 2.1563 - val_accuracy: 0.2333\n",
      "Epoch 750/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4239 - accuracy: 0.4329 - val_loss: 2.1629 - val_accuracy: 0.2300\n",
      "Epoch 751/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4224 - accuracy: 0.4171 - val_loss: 2.1794 - val_accuracy: 0.2400\n",
      "Epoch 752/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4233 - accuracy: 0.4243 - val_loss: 2.1854 - val_accuracy: 0.2367\n",
      "Epoch 753/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4223 - accuracy: 0.4257 - val_loss: 2.2051 - val_accuracy: 0.2333\n",
      "Epoch 754/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4235 - accuracy: 0.4271 - val_loss: 2.1869 - val_accuracy: 0.2333\n",
      "Epoch 755/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4221 - accuracy: 0.4386 - val_loss: 2.1849 - val_accuracy: 0.2467\n",
      "Epoch 756/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4223 - accuracy: 0.4143 - val_loss: 2.1829 - val_accuracy: 0.2400\n",
      "Epoch 757/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4233 - accuracy: 0.4200 - val_loss: 2.1907 - val_accuracy: 0.2433\n",
      "Epoch 758/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4220 - accuracy: 0.4300 - val_loss: 2.1885 - val_accuracy: 0.2433\n",
      "Epoch 759/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4221 - accuracy: 0.4271 - val_loss: 2.1786 - val_accuracy: 0.2400\n",
      "Epoch 760/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4218 - accuracy: 0.4329 - val_loss: 2.1784 - val_accuracy: 0.2400\n",
      "Epoch 761/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4215 - accuracy: 0.4229 - val_loss: 2.2086 - val_accuracy: 0.2500\n",
      "Epoch 762/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4225 - accuracy: 0.4257 - val_loss: 2.1981 - val_accuracy: 0.2400\n",
      "Epoch 763/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4215 - accuracy: 0.4200 - val_loss: 2.1838 - val_accuracy: 0.2400\n",
      "Epoch 764/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4227 - accuracy: 0.4300 - val_loss: 2.2048 - val_accuracy: 0.2433\n",
      "Epoch 765/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4203 - accuracy: 0.4214 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 766/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4217 - accuracy: 0.4214 - val_loss: 2.1842 - val_accuracy: 0.2400\n",
      "Epoch 767/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4217 - accuracy: 0.4257 - val_loss: 2.1846 - val_accuracy: 0.2367\n",
      "Epoch 768/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4205 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 769/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4207 - accuracy: 0.4243 - val_loss: 2.1856 - val_accuracy: 0.2367\n",
      "Epoch 770/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4200 - accuracy: 0.4214 - val_loss: 2.1758 - val_accuracy: 0.2333\n",
      "Epoch 771/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1942 - val_accuracy: 0.2367\n",
      "Epoch 772/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4202 - accuracy: 0.4229 - val_loss: 2.1983 - val_accuracy: 0.2433\n",
      "Epoch 773/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4200 - accuracy: 0.4229 - val_loss: 2.2066 - val_accuracy: 0.2500\n",
      "Epoch 774/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4191 - accuracy: 0.4243 - val_loss: 2.2019 - val_accuracy: 0.2400\n",
      "Epoch 775/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4182 - accuracy: 0.4286 - val_loss: 2.2032 - val_accuracy: 0.2533\n",
      "Epoch 776/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4193 - accuracy: 0.4271 - val_loss: 2.1977 - val_accuracy: 0.2467\n",
      "Epoch 777/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4177 - accuracy: 0.4314 - val_loss: 2.2090 - val_accuracy: 0.2333\n",
      "Epoch 778/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4190 - accuracy: 0.4214 - val_loss: 2.1922 - val_accuracy: 0.2333\n",
      "Epoch 779/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4191 - accuracy: 0.4300 - val_loss: 2.1962 - val_accuracy: 0.2333\n",
      "Epoch 780/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4190 - accuracy: 0.4229 - val_loss: 2.1879 - val_accuracy: 0.2400\n",
      "Epoch 781/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4196 - accuracy: 0.4214 - val_loss: 2.1973 - val_accuracy: 0.2467\n",
      "Epoch 782/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4184 - accuracy: 0.4257 - val_loss: 2.1738 - val_accuracy: 0.2400\n",
      "Epoch 783/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4186 - accuracy: 0.4329 - val_loss: 2.2047 - val_accuracy: 0.2433\n",
      "Epoch 784/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4181 - accuracy: 0.4300 - val_loss: 2.2132 - val_accuracy: 0.2400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4179 - accuracy: 0.4271 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 786/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4180 - accuracy: 0.4271 - val_loss: 2.1994 - val_accuracy: 0.2467\n",
      "Epoch 787/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4184 - accuracy: 0.4243 - val_loss: 2.1838 - val_accuracy: 0.2500\n",
      "Epoch 788/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4178 - accuracy: 0.4271 - val_loss: 2.1991 - val_accuracy: 0.2400\n",
      "Epoch 789/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4173 - accuracy: 0.4229 - val_loss: 2.1994 - val_accuracy: 0.2400\n",
      "Epoch 790/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4174 - accuracy: 0.4314 - val_loss: 2.2033 - val_accuracy: 0.2400\n",
      "Epoch 791/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4164 - accuracy: 0.4286 - val_loss: 2.2056 - val_accuracy: 0.2500\n",
      "Epoch 792/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4171 - accuracy: 0.4229 - val_loss: 2.1936 - val_accuracy: 0.2367\n",
      "Epoch 793/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4166 - accuracy: 0.4257 - val_loss: 2.2141 - val_accuracy: 0.2500\n",
      "Epoch 794/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4169 - accuracy: 0.4271 - val_loss: 2.2061 - val_accuracy: 0.2367\n",
      "Epoch 795/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4164 - accuracy: 0.4314 - val_loss: 2.2030 - val_accuracy: 0.2400\n",
      "Epoch 796/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4160 - accuracy: 0.4300 - val_loss: 2.2047 - val_accuracy: 0.2367\n",
      "Epoch 797/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4164 - accuracy: 0.4200 - val_loss: 2.2128 - val_accuracy: 0.2367\n",
      "Epoch 798/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4162 - accuracy: 0.4386 - val_loss: 2.2137 - val_accuracy: 0.2400\n",
      "Epoch 799/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4152 - accuracy: 0.4329 - val_loss: 2.2049 - val_accuracy: 0.2567\n",
      "Epoch 800/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4159 - accuracy: 0.4200 - val_loss: 2.2158 - val_accuracy: 0.2333\n",
      "Epoch 801/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4159 - accuracy: 0.4329 - val_loss: 2.2122 - val_accuracy: 0.2333\n",
      "Epoch 802/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4158 - accuracy: 0.4329 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 803/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4146 - accuracy: 0.4271 - val_loss: 2.2121 - val_accuracy: 0.2600\n",
      "Epoch 804/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4148 - accuracy: 0.4243 - val_loss: 2.2039 - val_accuracy: 0.2433\n",
      "Epoch 805/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4143 - accuracy: 0.4329 - val_loss: 2.2054 - val_accuracy: 0.2467\n",
      "Epoch 806/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4148 - accuracy: 0.4357 - val_loss: 2.2052 - val_accuracy: 0.2400\n",
      "Epoch 807/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4148 - accuracy: 0.4386 - val_loss: 2.2125 - val_accuracy: 0.2500\n",
      "Epoch 808/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4143 - accuracy: 0.4314 - val_loss: 2.2125 - val_accuracy: 0.2400\n",
      "Epoch 809/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4150 - accuracy: 0.4229 - val_loss: 2.2137 - val_accuracy: 0.2467\n",
      "Epoch 810/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4139 - accuracy: 0.4357 - val_loss: 2.2157 - val_accuracy: 0.2367\n",
      "Epoch 811/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4142 - accuracy: 0.4314 - val_loss: 2.2169 - val_accuracy: 0.2400\n",
      "Epoch 812/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4141 - accuracy: 0.4271 - val_loss: 2.2032 - val_accuracy: 0.2400\n",
      "Epoch 813/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4139 - accuracy: 0.4329 - val_loss: 2.2245 - val_accuracy: 0.2400\n",
      "Epoch 814/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4131 - accuracy: 0.4286 - val_loss: 2.2157 - val_accuracy: 0.2533\n",
      "Epoch 815/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4139 - accuracy: 0.4314 - val_loss: 2.2224 - val_accuracy: 0.2467\n",
      "Epoch 816/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4136 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 817/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4116 - accuracy: 0.4300 - val_loss: 2.2146 - val_accuracy: 0.2367\n",
      "Epoch 818/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4123 - accuracy: 0.4286 - val_loss: 2.2243 - val_accuracy: 0.2367\n",
      "Epoch 819/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4110 - accuracy: 0.4357 - val_loss: 2.2386 - val_accuracy: 0.2600\n",
      "Epoch 820/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4131 - accuracy: 0.4329 - val_loss: 2.2190 - val_accuracy: 0.2567\n",
      "Epoch 821/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4129 - accuracy: 0.4300 - val_loss: 2.2348 - val_accuracy: 0.2467\n",
      "Epoch 822/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4130 - accuracy: 0.4329 - val_loss: 2.2198 - val_accuracy: 0.2367\n",
      "Epoch 823/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4114 - accuracy: 0.4271 - val_loss: 2.2264 - val_accuracy: 0.2433\n",
      "Epoch 824/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4110 - accuracy: 0.4300 - val_loss: 2.2265 - val_accuracy: 0.2433\n",
      "Epoch 825/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4112 - accuracy: 0.4314 - val_loss: 2.2452 - val_accuracy: 0.2467\n",
      "Epoch 826/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4122 - accuracy: 0.4271 - val_loss: 2.2332 - val_accuracy: 0.2467\n",
      "Epoch 827/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4112 - accuracy: 0.4300 - val_loss: 2.2318 - val_accuracy: 0.2400\n",
      "Epoch 828/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4118 - accuracy: 0.4343 - val_loss: 2.2184 - val_accuracy: 0.2367\n",
      "Epoch 829/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4111 - accuracy: 0.4314 - val_loss: 2.2233 - val_accuracy: 0.2433\n",
      "Epoch 830/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4104 - accuracy: 0.4271 - val_loss: 2.2284 - val_accuracy: 0.2400\n",
      "Epoch 831/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4105 - accuracy: 0.4443 - val_loss: 2.2469 - val_accuracy: 0.2467\n",
      "Epoch 832/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4111 - accuracy: 0.4343 - val_loss: 2.2477 - val_accuracy: 0.2500\n",
      "Epoch 833/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4110 - accuracy: 0.4243 - val_loss: 2.2534 - val_accuracy: 0.2467\n",
      "Epoch 834/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4106 - accuracy: 0.4329 - val_loss: 2.2659 - val_accuracy: 0.2433\n",
      "Epoch 835/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4095 - accuracy: 0.4300 - val_loss: 2.2260 - val_accuracy: 0.2367\n",
      "Epoch 836/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2500\n",
      "Epoch 837/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4102 - accuracy: 0.4300 - val_loss: 2.2211 - val_accuracy: 0.2433\n",
      "Epoch 838/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4107 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 839/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4088 - accuracy: 0.4300 - val_loss: 2.2353 - val_accuracy: 0.2367\n",
      "Epoch 840/1000\n",
      "700/700 [==============================] - 0s 82us/step - loss: 1.4081 - accuracy: 0.4343 - val_loss: 2.2224 - val_accuracy: 0.2433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 841/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4092 - accuracy: 0.4371 - val_loss: 2.2331 - val_accuracy: 0.2367\n",
      "Epoch 842/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.4098 - accuracy: 0.4271 - val_loss: 2.2487 - val_accuracy: 0.2500\n",
      "Epoch 843/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4090 - accuracy: 0.4314 - val_loss: 2.2326 - val_accuracy: 0.2367\n",
      "Epoch 844/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4082 - accuracy: 0.4300 - val_loss: 2.2510 - val_accuracy: 0.2367\n",
      "Epoch 845/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4088 - accuracy: 0.4314 - val_loss: 2.2242 - val_accuracy: 0.2367\n",
      "Epoch 846/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4092 - accuracy: 0.4357 - val_loss: 2.2349 - val_accuracy: 0.2400\n",
      "Epoch 847/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4075 - accuracy: 0.4229 - val_loss: 2.2487 - val_accuracy: 0.2433\n",
      "Epoch 848/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4079 - accuracy: 0.4371 - val_loss: 2.2414 - val_accuracy: 0.2533\n",
      "Epoch 849/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4086 - accuracy: 0.4300 - val_loss: 2.2446 - val_accuracy: 0.2433\n",
      "Epoch 850/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4071 - accuracy: 0.4314 - val_loss: 2.2355 - val_accuracy: 0.2367\n",
      "Epoch 851/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4071 - accuracy: 0.4229 - val_loss: 2.2345 - val_accuracy: 0.2333\n",
      "Epoch 852/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4086 - accuracy: 0.4371 - val_loss: 2.2389 - val_accuracy: 0.2433\n",
      "Epoch 853/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4066 - accuracy: 0.4329 - val_loss: 2.2368 - val_accuracy: 0.2367\n",
      "Epoch 854/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4046 - accuracy: 0.4371 - val_loss: 2.2682 - val_accuracy: 0.2600\n",
      "Epoch 855/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4074 - accuracy: 0.4271 - val_loss: 2.2383 - val_accuracy: 0.2333\n",
      "Epoch 856/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4074 - accuracy: 0.4357 - val_loss: 2.2498 - val_accuracy: 0.2500\n",
      "Epoch 857/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4067 - accuracy: 0.4286 - val_loss: 2.2486 - val_accuracy: 0.2467\n",
      "Epoch 858/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4066 - accuracy: 0.4343 - val_loss: 2.2459 - val_accuracy: 0.2367\n",
      "Epoch 859/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2438 - val_accuracy: 0.2367\n",
      "Epoch 860/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4057 - accuracy: 0.4357 - val_loss: 2.2736 - val_accuracy: 0.2533\n",
      "Epoch 861/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4064 - accuracy: 0.4343 - val_loss: 2.2575 - val_accuracy: 0.2433\n",
      "Epoch 862/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4071 - accuracy: 0.4271 - val_loss: 2.2603 - val_accuracy: 0.2533\n",
      "Epoch 863/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4055 - accuracy: 0.4329 - val_loss: 2.2607 - val_accuracy: 0.2500\n",
      "Epoch 864/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4053 - accuracy: 0.4329 - val_loss: 2.2554 - val_accuracy: 0.2533\n",
      "Epoch 865/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4047 - accuracy: 0.4386 - val_loss: 2.2618 - val_accuracy: 0.2633\n",
      "Epoch 866/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4049 - accuracy: 0.4314 - val_loss: 2.2232 - val_accuracy: 0.2433\n",
      "Epoch 867/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4052 - accuracy: 0.4357 - val_loss: 2.2613 - val_accuracy: 0.2433\n",
      "Epoch 868/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4054 - accuracy: 0.4357 - val_loss: 2.2531 - val_accuracy: 0.2467\n",
      "Epoch 869/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4050 - accuracy: 0.4386 - val_loss: 2.2509 - val_accuracy: 0.2400\n",
      "Epoch 870/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4034 - accuracy: 0.4357 - val_loss: 2.2675 - val_accuracy: 0.2467\n",
      "Epoch 871/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4048 - accuracy: 0.4314 - val_loss: 2.2729 - val_accuracy: 0.2467\n",
      "Epoch 872/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4037 - accuracy: 0.4357 - val_loss: 2.2533 - val_accuracy: 0.2567\n",
      "Epoch 873/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2292 - val_accuracy: 0.2367\n",
      "Epoch 874/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4048 - accuracy: 0.4329 - val_loss: 2.2420 - val_accuracy: 0.2367\n",
      "Epoch 875/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4038 - accuracy: 0.4329 - val_loss: 2.2705 - val_accuracy: 0.2467\n",
      "Epoch 876/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4035 - accuracy: 0.4314 - val_loss: 2.2423 - val_accuracy: 0.2433\n",
      "Epoch 877/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4037 - accuracy: 0.4271 - val_loss: 2.2683 - val_accuracy: 0.2367\n",
      "Epoch 878/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.4042 - accuracy: 0.4343 - val_loss: 2.2634 - val_accuracy: 0.2400\n",
      "Epoch 879/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4012 - accuracy: 0.4371 - val_loss: 2.2625 - val_accuracy: 0.2400\n",
      "Epoch 880/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4051 - accuracy: 0.4329 - val_loss: 2.2507 - val_accuracy: 0.2400\n",
      "Epoch 881/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4035 - accuracy: 0.4429 - val_loss: 2.2849 - val_accuracy: 0.2500\n",
      "Epoch 882/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4035 - accuracy: 0.4371 - val_loss: 2.2680 - val_accuracy: 0.2400\n",
      "Epoch 883/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4044 - accuracy: 0.4286 - val_loss: 2.2364 - val_accuracy: 0.2400\n",
      "Epoch 884/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4027 - accuracy: 0.4314 - val_loss: 2.2784 - val_accuracy: 0.2533\n",
      "Epoch 885/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4031 - accuracy: 0.4314 - val_loss: 2.2322 - val_accuracy: 0.2433\n",
      "Epoch 886/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4036 - accuracy: 0.4386 - val_loss: 2.2614 - val_accuracy: 0.2467\n",
      "Epoch 887/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.4026 - accuracy: 0.4371 - val_loss: 2.2456 - val_accuracy: 0.2367\n",
      "Epoch 888/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4027 - accuracy: 0.4357 - val_loss: 2.2595 - val_accuracy: 0.2400\n",
      "Epoch 889/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4010 - accuracy: 0.4443 - val_loss: 2.2736 - val_accuracy: 0.2600\n",
      "Epoch 890/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4028 - accuracy: 0.4386 - val_loss: 2.2630 - val_accuracy: 0.2567\n",
      "Epoch 891/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.4024 - accuracy: 0.4271 - val_loss: 2.2669 - val_accuracy: 0.2433\n",
      "Epoch 892/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.4024 - accuracy: 0.4357 - val_loss: 2.2699 - val_accuracy: 0.2433\n",
      "Epoch 893/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4018 - accuracy: 0.4357 - val_loss: 2.2777 - val_accuracy: 0.2433\n",
      "Epoch 894/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4020 - accuracy: 0.4429 - val_loss: 2.2620 - val_accuracy: 0.2400\n",
      "Epoch 895/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4012 - accuracy: 0.4343 - val_loss: 2.2655 - val_accuracy: 0.2467\n",
      "Epoch 896/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.4014 - accuracy: 0.4357 - val_loss: 2.2715 - val_accuracy: 0.2600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 897/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4017 - accuracy: 0.4343 - val_loss: 2.2648 - val_accuracy: 0.2533\n",
      "Epoch 898/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4011 - accuracy: 0.4386 - val_loss: 2.2896 - val_accuracy: 0.2467\n",
      "Epoch 899/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4015 - accuracy: 0.4343 - val_loss: 2.2583 - val_accuracy: 0.2467\n",
      "Epoch 900/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4001 - accuracy: 0.4471 - val_loss: 2.2617 - val_accuracy: 0.2467\n",
      "Epoch 901/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3999 - accuracy: 0.4400 - val_loss: 2.2772 - val_accuracy: 0.2533\n",
      "Epoch 902/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4001 - accuracy: 0.4343 - val_loss: 2.2689 - val_accuracy: 0.2467\n",
      "Epoch 903/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3992 - accuracy: 0.4414 - val_loss: 2.2865 - val_accuracy: 0.2633\n",
      "Epoch 904/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3991 - accuracy: 0.4357 - val_loss: 2.2582 - val_accuracy: 0.2400\n",
      "Epoch 905/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4010 - accuracy: 0.4400 - val_loss: 2.2543 - val_accuracy: 0.2400\n",
      "Epoch 906/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3998 - accuracy: 0.4371 - val_loss: 2.2494 - val_accuracy: 0.2367\n",
      "Epoch 907/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.4003 - accuracy: 0.4386 - val_loss: 2.2830 - val_accuracy: 0.2467\n",
      "Epoch 908/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3997 - accuracy: 0.4414 - val_loss: 2.2715 - val_accuracy: 0.2433\n",
      "Epoch 909/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3993 - accuracy: 0.4329 - val_loss: 2.2790 - val_accuracy: 0.2500\n",
      "Epoch 910/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4004 - accuracy: 0.4357 - val_loss: 2.2561 - val_accuracy: 0.2400\n",
      "Epoch 911/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3991 - accuracy: 0.4371 - val_loss: 2.2786 - val_accuracy: 0.2367\n",
      "Epoch 912/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3995 - accuracy: 0.4400 - val_loss: 2.2665 - val_accuracy: 0.2367\n",
      "Epoch 913/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.4000 - accuracy: 0.4371 - val_loss: 2.2924 - val_accuracy: 0.2433\n",
      "Epoch 914/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3988 - accuracy: 0.4386 - val_loss: 2.2909 - val_accuracy: 0.2567\n",
      "Epoch 915/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3990 - accuracy: 0.4343 - val_loss: 2.2737 - val_accuracy: 0.2467\n",
      "Epoch 916/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3987 - accuracy: 0.4386 - val_loss: 2.2810 - val_accuracy: 0.2400\n",
      "Epoch 917/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3978 - accuracy: 0.4400 - val_loss: 2.2807 - val_accuracy: 0.2400\n",
      "Epoch 918/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3970 - accuracy: 0.4386 - val_loss: 2.2802 - val_accuracy: 0.2533\n",
      "Epoch 919/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3984 - accuracy: 0.4329 - val_loss: 2.2901 - val_accuracy: 0.2433\n",
      "Epoch 920/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3988 - accuracy: 0.4343 - val_loss: 2.2681 - val_accuracy: 0.2500\n",
      "Epoch 921/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3984 - accuracy: 0.4357 - val_loss: 2.2706 - val_accuracy: 0.2400\n",
      "Epoch 922/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3967 - accuracy: 0.4400 - val_loss: 2.2872 - val_accuracy: 0.2500\n",
      "Epoch 923/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3966 - accuracy: 0.4386 - val_loss: 2.2698 - val_accuracy: 0.2567\n",
      "Epoch 924/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3988 - accuracy: 0.4414 - val_loss: 2.2782 - val_accuracy: 0.2467\n",
      "Epoch 925/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3970 - accuracy: 0.4343 - val_loss: 2.2855 - val_accuracy: 0.2367\n",
      "Epoch 926/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3972 - accuracy: 0.4443 - val_loss: 2.2793 - val_accuracy: 0.2467\n",
      "Epoch 927/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3975 - accuracy: 0.4357 - val_loss: 2.2798 - val_accuracy: 0.2400\n",
      "Epoch 928/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3971 - accuracy: 0.4400 - val_loss: 2.3013 - val_accuracy: 0.2433\n",
      "Epoch 929/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3971 - accuracy: 0.4414 - val_loss: 2.2997 - val_accuracy: 0.2400\n",
      "Epoch 930/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3971 - accuracy: 0.4357 - val_loss: 2.2816 - val_accuracy: 0.2467\n",
      "Epoch 931/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3967 - accuracy: 0.4329 - val_loss: 2.2836 - val_accuracy: 0.2467\n",
      "Epoch 932/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3962 - accuracy: 0.4400 - val_loss: 2.2720 - val_accuracy: 0.2500\n",
      "Epoch 933/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3966 - accuracy: 0.4314 - val_loss: 2.2861 - val_accuracy: 0.2467\n",
      "Epoch 934/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3958 - accuracy: 0.4414 - val_loss: 2.2939 - val_accuracy: 0.2500\n",
      "Epoch 935/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3966 - accuracy: 0.4414 - val_loss: 2.2901 - val_accuracy: 0.2500\n",
      "Epoch 936/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3965 - accuracy: 0.4429 - val_loss: 2.2962 - val_accuracy: 0.2500\n",
      "Epoch 937/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3960 - accuracy: 0.4400 - val_loss: 2.2877 - val_accuracy: 0.2367\n",
      "Epoch 938/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3953 - accuracy: 0.4443 - val_loss: 2.2991 - val_accuracy: 0.2500\n",
      "Epoch 939/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3953 - accuracy: 0.4386 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 940/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3960 - accuracy: 0.4343 - val_loss: 2.2826 - val_accuracy: 0.2400\n",
      "Epoch 941/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3957 - accuracy: 0.4343 - val_loss: 2.2917 - val_accuracy: 0.2400\n",
      "Epoch 942/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3947 - accuracy: 0.4357 - val_loss: 2.2695 - val_accuracy: 0.2333\n",
      "Epoch 943/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3955 - accuracy: 0.4414 - val_loss: 2.3028 - val_accuracy: 0.2433\n",
      "Epoch 944/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3944 - accuracy: 0.4371 - val_loss: 2.3057 - val_accuracy: 0.2433\n",
      "Epoch 945/1000\n",
      "700/700 [==============================] - 0s 76us/step - loss: 1.3947 - accuracy: 0.4329 - val_loss: 2.3010 - val_accuracy: 0.2500\n",
      "Epoch 946/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3945 - accuracy: 0.4329 - val_loss: 2.2912 - val_accuracy: 0.2467\n",
      "Epoch 947/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3939 - accuracy: 0.4414 - val_loss: 2.3067 - val_accuracy: 0.2533\n",
      "Epoch 948/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3940 - accuracy: 0.4300 - val_loss: 2.2777 - val_accuracy: 0.2367\n",
      "Epoch 949/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3938 - accuracy: 0.4471 - val_loss: 2.2906 - val_accuracy: 0.2400\n",
      "Epoch 950/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3929 - accuracy: 0.4386 - val_loss: 2.2916 - val_accuracy: 0.2367\n",
      "Epoch 951/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3940 - accuracy: 0.4429 - val_loss: 2.3014 - val_accuracy: 0.2500\n",
      "Epoch 952/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3938 - accuracy: 0.4414 - val_loss: 2.2949 - val_accuracy: 0.2467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 953/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3935 - accuracy: 0.4371 - val_loss: 2.3148 - val_accuracy: 0.2533\n",
      "Epoch 954/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3940 - accuracy: 0.4471 - val_loss: 2.2962 - val_accuracy: 0.2567\n",
      "Epoch 955/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3936 - accuracy: 0.4429 - val_loss: 2.3098 - val_accuracy: 0.2500\n",
      "Epoch 956/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3928 - accuracy: 0.4386 - val_loss: 2.3181 - val_accuracy: 0.2433\n",
      "Epoch 957/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3925 - accuracy: 0.4414 - val_loss: 2.2925 - val_accuracy: 0.2433\n",
      "Epoch 958/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3938 - accuracy: 0.4343 - val_loss: 2.3365 - val_accuracy: 0.2467\n",
      "Epoch 959/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3936 - accuracy: 0.4414 - val_loss: 2.2892 - val_accuracy: 0.2467\n",
      "Epoch 960/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3930 - accuracy: 0.4400 - val_loss: 2.3049 - val_accuracy: 0.2467\n",
      "Epoch 961/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.2714 - val_accuracy: 0.2467\n",
      "Epoch 962/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3931 - accuracy: 0.4400 - val_loss: 2.3025 - val_accuracy: 0.2467\n",
      "Epoch 963/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3926 - accuracy: 0.4386 - val_loss: 2.2963 - val_accuracy: 0.2500\n",
      "Epoch 964/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3919 - accuracy: 0.4357 - val_loss: 2.2856 - val_accuracy: 0.2433\n",
      "Epoch 965/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3913 - accuracy: 0.4414 - val_loss: 2.2959 - val_accuracy: 0.2533\n",
      "Epoch 966/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3924 - accuracy: 0.4429 - val_loss: 2.3148 - val_accuracy: 0.2567\n",
      "Epoch 967/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3923 - accuracy: 0.4429 - val_loss: 2.3105 - val_accuracy: 0.2467\n",
      "Epoch 968/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3913 - accuracy: 0.4400 - val_loss: 2.2989 - val_accuracy: 0.2433\n",
      "Epoch 969/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3917 - accuracy: 0.4414 - val_loss: 2.3052 - val_accuracy: 0.2433\n",
      "Epoch 970/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3916 - accuracy: 0.4400 - val_loss: 2.3201 - val_accuracy: 0.2400\n",
      "Epoch 971/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3916 - accuracy: 0.4414 - val_loss: 2.3001 - val_accuracy: 0.2467\n",
      "Epoch 972/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3913 - accuracy: 0.4386 - val_loss: 2.3213 - val_accuracy: 0.2333\n",
      "Epoch 973/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3901 - accuracy: 0.4400 - val_loss: 2.3114 - val_accuracy: 0.2500\n",
      "Epoch 974/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3908 - accuracy: 0.4386 - val_loss: 2.3123 - val_accuracy: 0.2500\n",
      "Epoch 975/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3907 - accuracy: 0.4443 - val_loss: 2.3262 - val_accuracy: 0.2500\n",
      "Epoch 976/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3905 - accuracy: 0.4429 - val_loss: 2.3076 - val_accuracy: 0.2500\n",
      "Epoch 977/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3905 - accuracy: 0.4343 - val_loss: 2.3044 - val_accuracy: 0.2400\n",
      "Epoch 978/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3904 - accuracy: 0.4486 - val_loss: 2.3117 - val_accuracy: 0.2533\n",
      "Epoch 979/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3081 - val_accuracy: 0.2467\n",
      "Epoch 980/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3906 - accuracy: 0.4429 - val_loss: 2.3256 - val_accuracy: 0.2500\n",
      "Epoch 981/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3894 - accuracy: 0.4371 - val_loss: 2.3378 - val_accuracy: 0.2500\n",
      "Epoch 982/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3902 - accuracy: 0.4400 - val_loss: 2.3157 - val_accuracy: 0.2533\n",
      "Epoch 983/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3897 - accuracy: 0.4357 - val_loss: 2.3231 - val_accuracy: 0.2500\n",
      "Epoch 984/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3898 - accuracy: 0.4414 - val_loss: 2.3133 - val_accuracy: 0.2500\n",
      "Epoch 985/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3891 - accuracy: 0.4400 - val_loss: 2.3245 - val_accuracy: 0.2367\n",
      "Epoch 986/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3891 - accuracy: 0.4414 - val_loss: 2.3228 - val_accuracy: 0.2500\n",
      "Epoch 987/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3887 - accuracy: 0.4414 - val_loss: 2.3043 - val_accuracy: 0.2400\n",
      "Epoch 988/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3886 - accuracy: 0.4429 - val_loss: 2.3385 - val_accuracy: 0.2633\n",
      "Epoch 989/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3903 - accuracy: 0.4357 - val_loss: 2.3375 - val_accuracy: 0.2533\n",
      "Epoch 990/1000\n",
      "700/700 [==============================] - 0s 72us/step - loss: 1.3887 - accuracy: 0.4443 - val_loss: 2.3547 - val_accuracy: 0.2533\n",
      "Epoch 991/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3890 - accuracy: 0.4471 - val_loss: 2.3138 - val_accuracy: 0.2433\n",
      "Epoch 992/1000\n",
      "700/700 [==============================] - 0s 77us/step - loss: 1.3888 - accuracy: 0.4371 - val_loss: 2.3301 - val_accuracy: 0.2400\n",
      "Epoch 993/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3885 - accuracy: 0.4457 - val_loss: 2.3353 - val_accuracy: 0.2533\n",
      "Epoch 994/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3885 - accuracy: 0.4357 - val_loss: 2.3073 - val_accuracy: 0.2367\n",
      "Epoch 995/1000\n",
      "700/700 [==============================] - 0s 79us/step - loss: 1.3890 - accuracy: 0.4429 - val_loss: 2.3282 - val_accuracy: 0.2500\n",
      "Epoch 996/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3877 - accuracy: 0.4457 - val_loss: 2.3284 - val_accuracy: 0.2467\n",
      "Epoch 997/1000\n",
      "700/700 [==============================] - 0s 75us/step - loss: 1.3879 - accuracy: 0.4429 - val_loss: 2.3277 - val_accuracy: 0.2533\n",
      "Epoch 998/1000\n",
      "700/700 [==============================] - 0s 74us/step - loss: 1.3887 - accuracy: 0.4386 - val_loss: 2.3401 - val_accuracy: 0.2533\n",
      "Epoch 999/1000\n",
      "700/700 [==============================] - 0s 73us/step - loss: 1.3881 - accuracy: 0.4386 - val_loss: 2.3246 - val_accuracy: 0.2500\n",
      "Epoch 1000/1000\n",
      "700/700 [==============================] - 0s 78us/step - loss: 1.3879 - accuracy: 0.4386 - val_loss: 2.3363 - val_accuracy: 0.2500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)\n",
    "\n",
    "# 1. Preparing the dataset.\n",
    "\n",
    "# Loading the train_set and test_set\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# Separate a validation_set from the train_set\n",
    "X_val = X_train[50000:]\n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "\n",
    "X_train = X_train.reshape(50000, 784).astype('float32') / 255.0\n",
    "X_val = X_val.reshape(10000, 784).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(10000, 784).astype('float32') / 255.0\n",
    "\n",
    "# Choose the set\n",
    "train_rand_idxs = np.random.choice(50000, 700)\n",
    "val_rand_idxs = np.random.choice(10000, 300)\n",
    "\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "X_val = X_val[val_rand_idxs]\n",
    "Y_val = Y_val[val_rand_idxs]\n",
    "\n",
    "# COnverting the Labeling\n",
    "Y_train = np_utils.to_categorical(Y_train)\n",
    "Y_val = np_utils.to_categorical(Y_val)\n",
    "Y_test = np_utils.to_categorical(Y_test)\n",
    "\n",
    "# 2. Configuring the models\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# 3. Compiling\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "\n",
    "# 4. Training the model\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val, Y_val))\n",
    "\n",
    "# 5. Displaying the Learning Process\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(hist.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
